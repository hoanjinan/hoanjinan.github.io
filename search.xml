<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Natural Language Processing (NLP)</title>
      <link href="/2019/09/02/Natural-Language-Processing/"/>
      <url>/2019/09/02/Natural-Language-Processing/</url>
      
        <content type="html"><![CDATA[<h1 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h1><h2 id="introduction-to-the-post"><a class="markdownIt-Anchor" href="#introduction-to-the-post"></a> Introduction to The Post</h2><p>Have you ever wondered how your email filters out spam messages?  Or maybe how autocorrect on your phone knows what you’re trying to type?  In this post, we’ll cover some basics of natural language processing like reading in and creating structure in messy text data, and then cleaning and tokenizing that data.  Then the post will cover some of the more advanced topics like lemmatising, stemming, and vectorizing the data.  In other words, converting it from text into a numeric matrix.  The post do this with a focus on preparing the data to build a machine learning classifier on top of it.  The post will also learn how to build two different types of machine learning models, while thoroughly testing and evaluating different variations of those models.  We’ll have the tools to go from messy dataset to concise and accurate predictions from machine learning model, to deliver solutions to complex business problems.</p><h2 id="introduction-to-natural-language-processing-nlp"><a class="markdownIt-Anchor" href="#introduction-to-natural-language-processing-nlp"></a> Introduction to Natural Language Processing (NLP)</h2><p>Natural language processing is a field concerned with the ability of a computer to understand, analyze, manipulate, and potentially generate human language. By human language, we’re simply referring to any language used for everyday communication.  This can be English, Spanish, French, anything like that.  Now it’s worth noting that Python doesn’t naturally know what any given word means.  All it will see is a string of characters.  For instance, it has no idea what natural actually means.  It sees that it’s seven characters long, but the individual characters don’t mean anything to Python and certainly the collection of those characters together don’t mean anything, either.  So we know that, what an N is, what an A is, and we know that together, those seven characters makes up the word natural, and we know what that means.  So NLP is the field of getting the computer to understand what naturally actually signifies, and from there we can get into the manipulation or potentially even generation of that human language.</p><p>You probably experience natural language processing on a daily basis.  They may not really even know it.  So here are a few examples that you may see on a day to day basis.  The first would be a spam filter, so this is just where your email server is determining whether an incoming email is spam or not, based on the content of the body, the subject, and maybe the email domain.  The second is auto-complete, where Google is basically predicting what you’re interested in searching for based on what you’ve already entered and what others commonly search for with those same phrases.  So if I search for natural language processing, it knows that many other people are interested in learning NLP with Python, or learning it through a course, or looking for jobs related to natural language processing.  So it can auto-complete your search for you.  The last is auto-correct, where say iPhone is trying to help you correct a misspelling. It shows how auto-correct has actually evolved over time and continues to evolve and learn by upgrading the operating system.  So with iOS 6, if you’re trying to say, “I’ll be ill tomorrow,” It wouldn’t necessarily correct I’ll be I’ll tomorrow until iOS 7, where it actually corrects, it auto-completes tomorrow and corrects I’ll into ill.  So it’ll correctly send as I’ll be ill tomorrow.  So that just kind of shows how NLP is still evolving and how a system like iOS is still kind of learning what natural language even means.</p><p>Now NLP is a very broad umbrella that encompasses many topics. A few of those might be sentiment analysis, topic modeling, text classification, and sentence segmentation or part-or-speech tagging.  The core component of natural language processing is extracting all the information from a block of text that is relevant to a computer understanding the language.  This is task specific, as well.  Different information is relevant for a sentiment analysis task than is relevant for a topic modeling task. So that’s a very quick introduction into what natural language processing is.</p><h2 id="introduction-to-nltk"><a class="markdownIt-Anchor" href="#introduction-to-nltk"></a> Introduction to NLTK</h2><p>The natural language toolkit is the most utilized package for handling natural language processing tasks in Python.  Usually called NLTK for short, it is a suite of open-source tools originally created in 2001 at the University of Pennsylvania for the purpose of making building NLP processes in Python easier.  This package has been expanded through the extensive contributions of open-source users in the years since its original development.  NLTK is great because it basically provides a jumpstart to building any NLP process by giving you the basic tools that you can then chain together to accomplish your goal rather than having to build all those tools from scratch and a lot of tools are packaged into NLTK.</p><h1 id="nlp-basics"><a class="markdownIt-Anchor" href="#nlp-basics"></a> NLP Basics</h1><h2 id="how-to-install-nltk-on-local-machine"><a class="markdownIt-Anchor" href="#how-to-install-nltk-on-local-machine"></a> How to install NLTK on local machine</h2><p>Both sets of instructions below assume you already have Python installed. These instructions are taken directly from <a href="http://www.nltk.org/install.html" target="_blank" rel="noopener">http://www.nltk.org/install.html</a>.</p><p><strong>Mac/Unix</strong></p><p>From the terminal:</p><ol><li>Install NLTK: run <code>pip install -U nltk</code></li><li>Test installation: run <code>python</code> then type <code>import nltk</code></li></ol><p><strong>Windows</strong></p><ol><li>Install NLTK: <a href="http://pypi.python.org/pypi/nltk" target="_blank" rel="noopener">http://pypi.python.org/pypi/nltk</a></li><li>Test installation: <code>Start&gt;Python35</code>, then type <code>import nltk</code></li></ol><h3 id="download-nltk-data"><a class="markdownIt-Anchor" href="#download-nltk-data"></a> Download NLTK data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download()</span><br></pre></td></tr></table></figure><p>The following images will show the downloader of NLTK:</p><p><img alt="NLTK All Packages Uninstalled" data-src="/img/NLP/NLTK_Uninstalled.png" class="lozad"></p><p>In above image, select ‘all packages’ and click ‘download’ button to start installing all NLTK packages.</p><p><img alt="NLTK All Packages Installed" data-src="/img/NLP/NLTK_Installed.png" class="lozad"></p><p>The above image shows that all NLTK packages have been installed.</p><p>Small example of using NLTK package:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"></span><br><span class="line">stopwords.words(<span class="string">"english"</span>)[<span class="number">0</span>:<span class="number">500</span>:<span class="number">25</span>]</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'i'</span>, <span class="string">'herself'</span>, <span class="string">'been'</span>, <span class="string">'with'</span>, <span class="string">'here'</span>, <span class="string">'very'</span>, <span class="string">'doesn'</span>, <span class="string">'won'</span>]</span><br></pre></td></tr></table></figure><h2 id="reading-in-text-data"><a class="markdownIt-Anchor" href="#reading-in-text-data"></a> Reading in Text Data</h2><h3 id="what-is-unstructured-data"><a class="markdownIt-Anchor" href="#what-is-unstructured-data"></a> What is Unstructured Data</h3><p>Unstructured data could mean that it’s binary data, it could mean no delimiters, or it could mean no indications of any rows.  A few examples might be an email, PDF file, social media post, these may just get dumped into a file with no indication of where, maybe, a subject of an email ends and the body of the email begins, or even where one email ends and the next begins.  It could also get cluttered by things like HTML tags and it can get really messy.  It’s important to note that Python is pretty smart, but ultimately, unless it’s told otherwise, it basically sees everything as a string of characters. It needs to be told what those characters mean.</p><h3 id="read-semi-structured-data"><a class="markdownIt-Anchor" href="#read-semi-structured-data"></a> Read Semi-structured data</h3><p>The following image presents a semi-structured SMS data:</p><p><img alt="Semi-structured SMS data sample" data-src="/img/NLP/SMS.png" class="lozad"></p><p>This dataset is a collection of text messages, each with a label of either spam or ham.  It’s not a clean CSV file, but it’s not terribly unstructured, either.  Each row has a distinct text message and a distinct label as either spam or ham. So, in the context of text datasets, this is actually pretty well structured, so this shouldn’t be too difficult.</p><p>Reading the data and print it out:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Read in the raw text</span></span><br><span class="line">rawData = open(<span class="string">"SMSSpamCollection.tsv"</span>).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the raw data</span></span><br><span class="line">rawData[<span class="number">0</span>:<span class="number">500</span>]</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"ham\tI've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\nspam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's\nham\tNah I don't think he goes to usf, he lives around here though\nham\tEven my brother is not like to speak with me. They treat me like aid"</span></span><br></pre></td></tr></table></figure><p>You could see that it’s just basically a block of text, and you’ll see that you have these \t and these \n separators. The \t’s are between the labels and the text message bodies, and the \n’s are typically at the end of those lines.</p><p>The following code is going to replace \n with \t and then split this into a list:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">parsedData = rawData.replace(<span class="string">"\t"</span>, <span class="string">"\n"</span>).split(<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">parsedData[<span class="number">0</span>:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'ham'</span>,</span><br><span class="line"> <span class="string">"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times."</span>,</span><br><span class="line"> <span class="string">'spam'</span>,</span><br><span class="line"> <span class="string">"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's"</span>,</span><br><span class="line"> <span class="string">'ham'</span>]</span><br></pre></td></tr></table></figure><p>Split the label and the text into lists:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">labelList = parsedData[<span class="number">0</span>::<span class="number">2</span>]</span><br><span class="line">textList = parsedData[<span class="number">1</span>::<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>Print the results:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(labelList[<span class="number">0</span>:<span class="number">5</span>])</span><br><span class="line">print(textList[<span class="number">0</span>:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'ham'</span>, <span class="string">'spam'</span>, <span class="string">'ham'</span>, <span class="string">'ham'</span>, <span class="string">'ham'</span>]</span><br><span class="line">[<span class="string">"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times."</span>, <span class="string">"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's"</span>, <span class="string">"Nah I don't think he goes to usf, he lives around here though"</span>, <span class="string">'Even my brother is not like to speak with me. They treat me like aids patent.'</span>, <span class="string">'I HAVE A DATE ON SUNDAY WITH WILL!!'</span>]</span><br></pre></td></tr></table></figure><p>Combine both lists and put them into pandas dataframe:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">fullCorpus = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">"label"</span>: labelList,</span><br><span class="line">    <span class="string">"body_list"</span>: textList</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">fullCorpus.head()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ValueError: arrays must all be same length</span><br></pre></td></tr></table></figure><p>Spot the error:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(len(labelList))</span><br><span class="line">print(len(textList))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">5571</span></span><br><span class="line"><span class="number">5570</span></span><br></pre></td></tr></table></figure><p>Print the last 5 values:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(labelList[<span class="number">-5</span>:])</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'ham'</span>, <span class="string">'ham'</span>, <span class="string">'ham'</span>, <span class="string">'ham'</span>, <span class="string">''</span>]</span><br></pre></td></tr></table></figure><p>Correction:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fullCorpus = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">"label"</span>: labelList[:<span class="number">-1</span>],</span><br><span class="line">    <span class="string">"body_list"</span>: textList</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">fullCorpus.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_list</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">ham</td><td style="text-align:center">I’ve been searching for the right words to tha…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup fina…</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I don’t think he goes to usf, he lives aro…</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me. …</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td></tr></tbody></table><p>Read the file using pandas:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset = pd.read_csv(<span class="string">"SMSSpamCollection.tsv"</span>, sep = <span class="string">"\t"</span>, header = <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">0</th><th style="text-align:center">1</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">ham</td><td style="text-align:center">I’ve been searching for the right words to tha…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup fina…</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I don’t think he goes to usf, he lives aro…</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me. …</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td></tr></tbody></table><h2 id="exploring-the-dataset"><a class="markdownIt-Anchor" href="#exploring-the-dataset"></a> Exploring The Dataset</h2><p>Before diving into any in-depth analysis, data cleaning or model building, we want to do some very high-level exploration of our data to understand what we’re working with.  So we might ask questions like what is the shape of our data, how many ham or spam are in our data set, and are there any missing values.  So this will inform the decisions that we make as we move forward.</p><p>Read the data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">fullCorpus = pd.read_csv(<span class="string">'SMSSpamCollection.tsv'</span>, sep=<span class="string">'\t'</span>, header=<span class="literal">None</span>)</span><br><span class="line">fullCorpus.columns = [<span class="string">"label"</span>, <span class="string">"body_text"</span>]</span><br><span class="line"></span><br><span class="line">fullCorpus.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_list</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">ham</td><td style="text-align:center">I’ve been searching for the right words to tha…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup fina…</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I don’t think he goes to usf, he lives aro…</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me. …</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td></tr></tbody></table><p>What is the shape of the dataset?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Input data has &#123;&#125; rows and &#123;&#125; columns"</span>.format(len(fullCorpus), len(fullCorpus.columns)))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Input data has <span class="number">5568</span> rows <span class="keyword">and</span> <span class="number">2</span> columns</span><br></pre></td></tr></table></figure><p>How many spam/ham are there?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Out of &#123;&#125; rows, &#123;&#125; are spam, &#123;&#125; are ham"</span>.format(len(fullCorpus),</span><br><span class="line">                                                       len(fullCorpus[fullCorpus[<span class="string">"label"</span>] == <span class="string">"spam"</span>]),</span><br><span class="line">                                                       len(fullCorpus[fullCorpus[<span class="string">"label"</span>] == <span class="string">"ham"</span>])))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Out of <span class="number">5568</span> rows, <span class="number">746</span> are spam, <span class="number">4822</span> are ham</span><br></pre></td></tr></table></figure><p>How much missing data is there?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Number of null in label: &#123;&#125;"</span>.format(fullCorpus[<span class="string">"label"</span>].isnull().sum()))</span><br><span class="line">print(<span class="string">"Number of null in text: &#123;&#125;"</span>.format(fullCorpus[<span class="string">"body_text"</span>].isnull().sum()))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Number of null <span class="keyword">in</span> label: <span class="number">0</span></span><br><span class="line">Number of null <span class="keyword">in</span> text: <span class="number">0</span></span><br></pre></td></tr></table></figure><p>This helped us better understand our data once we actually got it read in. The insights pulled from this very basic exploration will help dictate how we approach the rest of our data cleaning and model building.</p><h2 id="regular-expressions"><a class="markdownIt-Anchor" href="#regular-expressions"></a> Regular Expressions</h2><h3 id="introduction-to-regular-expression"><a class="markdownIt-Anchor" href="#introduction-to-regular-expression"></a> Introduction to Regular Expression</h3><p>A regular expression, or a regex for short is a text string used for describing a certain search pattern.  So if you’re familiar with wildcards for search, like if you wanted to search for any CSV file on your computer using *.csv, this is basically just a supercharged version of that.  Regular expressions can take various forms.</p><p>To give a very quick example of what it means, the regular expression ‘nlp’ will just search for the explicit “nlp” string within some other string.  This isn’t so much a search pattern as it is an explicit command for what we want to find.  So if it was, “I love nlp” then this search pattern would just capture and return “nlp.”  Another way to identify the “nlp” string would be to use the expression ‘[j-q]’.  And this will just search for all single characters between ‘j’ and ‘q’ in whatever text we’re looking at, but this will search for all characters between ‘j’ and ‘q’, not just ‘n’, ‘l’, and ‘p’.  The other consideration here is that this will only return single characters at a time.  So this would return ‘n’ and then ‘l’ and then ‘p’ and also whatever other characters between ‘j’ and ‘q’ in your text string.  This isn’t usually what we’re looking for.  So we can solve that issue of only returning a single character by simply placing a plus sign outside of our brackets like ‘[j-q]+’.  What that will tell Python is that it can search for strings longer than one character.  So what this will look for is any character between ‘j’ and ‘q’, just with the added flexibility of returning strings of multiple characters together that are between ‘j’ and ‘q’.  Switching gears a little bit, ‘[0-9]+’ will return all numbers with the flexibility of returning sequences of more than one number.  So if there’s a year, like 2017, it will return the full year, rather than each number individually.  Then lastly, to combine these two concepts, ‘[j-q0-9]+’ will search for sequences of characters between ‘j’ and ‘q’, or numbers between 0 and 9.  So if you had a course name that was “nlp2017” without any spaces, then it would return that full string, but if you had “nlp 2017” with a space in between them, then that would return them as two separate sequences.  This is just five very quick examples, but there is literally an infinite number of patters that you could come up with.</p><p>Regex give you the power and flexibility to search for almost any kind of pattern you could imagine.  The examples are useful, but why do we actually care about this?  Regexes are particularly useful when dealing with text data because a lot of the data is unstructured, where you need to be able to use these patterns to try to create some structure within the document.  For instance, you could use a regex to identify the white space between words or tokens, or even let Python know how to split up a certain sentence.  Another use is to identify delimiters between columns or end-of-line escape characters that indicate the end of one line and the beginning of another like we saw in our SMS Spam Collection dataset.  They can also be used to remove punctuation or numbers, clean HTML tags, or just identify some random patterns that you’re interested in.  A few examples of regular use cases might be confirming passwords that meet some criteria.  So maybe a company requires one capital letter, one lower case and one special character in their passwords.  You can create a regex to confirm that each new password created matches that criteria.  Then the last three all kind of fall under the same broad category of searching for a certain pattern, like filenames, so find all the CSV’s that meet this criteria, or some portion of a URL, so maybe it’s whatever follows .com or .org, or scraping for key information from a larger document like package version numbers from a technical report.</p><h3 id="how-to-use-regular-expressions"><a class="markdownIt-Anchor" href="#how-to-use-regular-expressions"></a> How to Use Regular Expressions</h3><p>The primary reason that we’re talking about regex is in order to tokenize sentences or split a sentence into a list of words so that Python can understand what it needs to be looking at.  Right now, Python just sees a string of characters, so we need to tell it what to focus on, and how to organize those characters.  For our machine learning model, Python will need to split the string into what we call tokens, or words, so that the model can learn how those tokens relate to the corresponse variable.</p><p>Python’s <code>re</code> package is the most commonly used regex resource. More details can be found <a href="https://docs.python.org/3/library/re.html" target="_blank" rel="noopener">here</a>.</p><p>Import <code>re</code> package and define 3 sentences:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">re_test = <span class="string">'This is a made up string to test 2 different regex methods'</span></span><br><span class="line">re_test_messy = <span class="string">'This      is a made up     string to test 2    different regex methods'</span></span><br><span class="line">re_test_messy1 = <span class="string">'This-is-a-made/up.string*to&gt;&gt;&gt;&gt;test----2""""""different~regex-methods'</span></span><br></pre></td></tr></table></figure><p>Splitting a sentence into a list of words:</p><p>First Sentance:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.split(<span class="string">"\s"</span>, re_test)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'This'</span>,</span><br><span class="line"> <span class="string">'is'</span>,</span><br><span class="line"> <span class="string">'a'</span>,</span><br><span class="line"> <span class="string">'made'</span>,</span><br><span class="line"> <span class="string">'up'</span>,</span><br><span class="line"> <span class="string">'string'</span>,</span><br><span class="line"> <span class="string">'to'</span>,</span><br><span class="line"> <span class="string">'test'</span>,</span><br><span class="line"> <span class="string">'2'</span>,</span><br><span class="line"> <span class="string">'different'</span>,</span><br><span class="line"> <span class="string">'regex'</span>,</span><br><span class="line"> <span class="string">'methods'</span>]</span><br></pre></td></tr></table></figure><p>Second Sentance:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Split on a space to find words</span></span><br><span class="line">re.split(<span class="string">"\s"</span>, re_test_messy)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'This'</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">'is'</span>,</span><br><span class="line"> <span class="string">'a'</span>,</span><br><span class="line"> <span class="string">'made'</span>,</span><br><span class="line"> <span class="string">'up'</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">'string'</span>,</span><br><span class="line"> <span class="string">'to'</span>,</span><br><span class="line"> <span class="string">'test'</span>,</span><br><span class="line"> <span class="string">'2'</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">'different'</span>,</span><br><span class="line"> <span class="string">'regex'</span>,</span><br><span class="line"> <span class="string">'methods'</span>]</span><br></pre></td></tr></table></figure><p>You can see that the above code doesn’t work well if there are more spaces between words.  The following code can solve this problem:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Split on maybe more than one spaces to find words</span></span><br><span class="line">re.split(<span class="string">"\s+"</span>, re_test_messy)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'This'</span>,</span><br><span class="line"> <span class="string">'is'</span>,</span><br><span class="line"> <span class="string">'a'</span>,</span><br><span class="line"> <span class="string">'made'</span>,</span><br><span class="line"> <span class="string">'up'</span>,</span><br><span class="line"> <span class="string">'string'</span>,</span><br><span class="line"> <span class="string">'to'</span>,</span><br><span class="line"> <span class="string">'test'</span>,</span><br><span class="line"> <span class="string">'2'</span>,</span><br><span class="line"> <span class="string">'different'</span>,</span><br><span class="line"> <span class="string">'regex'</span>,</span><br><span class="line"> <span class="string">'methods'</span>]</span><br></pre></td></tr></table></figure><p>Let’s try the third sentance:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.split(<span class="string">"\s+"</span>, re_test_messy1)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'This-is-a-made/up.string*to&gt;&gt;&gt;&gt;test----2""""""different~regex-methods'</span>]</span><br></pre></td></tr></table></figure><p>As you can see that the code above only looks for spaces but the third sentance contains lots of special characters so the code will not work on this sentance.  However, the following code fix this problem by only searching non word characters.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.split(<span class="string">"\W+"</span>, re_test_messy1)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'This'</span>,</span><br><span class="line"> <span class="string">'is'</span>,</span><br><span class="line"> <span class="string">'a'</span>,</span><br><span class="line"> <span class="string">'made'</span>,</span><br><span class="line"> <span class="string">'up'</span>,</span><br><span class="line"> <span class="string">'string'</span>,</span><br><span class="line"> <span class="string">'to'</span>,</span><br><span class="line"> <span class="string">'test'</span>,</span><br><span class="line"> <span class="string">'2'</span>,</span><br><span class="line"> <span class="string">'different'</span>,</span><br><span class="line"> <span class="string">'regex'</span>,</span><br><span class="line"> <span class="string">'methods'</span>]</span><br></pre></td></tr></table></figure><p>There are other two options that can search all useful words instead of searching for non words but give the same result in the end.  The following 3 lines of code will show you how it does.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">re.findall(<span class="string">"\S+"</span>, re_test)</span><br><span class="line"></span><br><span class="line">re.findall(<span class="string">"\S+"</span>, re_test_messy)</span><br><span class="line"></span><br><span class="line">re.findall(<span class="string">"\w+"</span>, re_test_messy1)</span><br></pre></td></tr></table></figure><p><em><strong>Notice: uppercase usually means the opposite of lowercase that lowercase searches for all specified instances but uppercase will search others instead of the specified instances</strong></em></p><p>So that’s how we can use two different methods from the re package along with several different regexes to properly tokenize messy sentences. Now that we’ve covered some of the basic regex usage for the purpose of tokenizing, there are a few takeaways to keep in mind. There are two methods from the re package that can be used for tokenizing. findall() will search for the actual words while ignoring the things that separate the words, while split() will search for the characters that split the words while ignoring the actual words themselves. And the regexes that are most useful for tokenizing, keep in mind that anything using a W is based on words, while anything with an S is based on white spaces. In our daily work, it’s much more common to be using the W regex because it allows the flexibility for words to be separated by spaces, or special characters. But having an understanding of what the S offers you is a nice tool to hold in your back pocket.</p><h3 id="regular-expression-replacements"><a class="markdownIt-Anchor" href="#regular-expression-replacements"></a> Regular Expression Replacements</h3><p>The following sentances are the examples that we need to capture a section of the sentance and replace with other words:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pep8_test = <span class="string">'I try to follow PEP8 guidelines'</span></span><br><span class="line">pep7_test = <span class="string">'I try to follow PEP7 guidelines'</span></span><br><span class="line">peep8_test = <span class="string">'I try to follow PEEP8 guidelines'</span></span><br></pre></td></tr></table></figure><p>We need to replace PEP8, PEP7 and PEEP8 with PEP8 Python Styleguide.  The following code is the experiment of this replacement:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">re.findall(<span class="string">"[a-z]+"</span>, pep8_test)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'try'</span>, <span class="string">'to'</span>, <span class="string">'follow'</span>, <span class="string">'guidelines'</span>]</span><br></pre></td></tr></table></figure><p>The above code is to find out all lower case words, but we need to find the uppercase ones, so we are going to change it like this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.findall(<span class="string">"[A-Z]+"</span>, pep8_test)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'I'</span>, <span class="string">'PEP'</span>]</span><br></pre></td></tr></table></figure><p>As you can notice from the output, it captures all uppercase word.  However, we also need digits in the end to get the output of PEP8, PEP7 and PEEP8.  Therefore, we simply put [0-9]+ to make it possible.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.findall(<span class="string">"[A-Z]+[0-9]+"</span>, peep8_test)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'PEEP8'</span>]</span><br></pre></td></tr></table></figure><p>Here is our final searching result, but we need to replace this section, how can we do?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(<span class="string">"[A-Z]+[0-9]+"</span>, <span class="string">"PEP8 Python Styleguide"</span>, peep8_test)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'I try to follow PEP8 Python Styleguide guidelines'</span></span><br></pre></td></tr></table></figure><p>You can see that the sub function can help us replacing our search section with another defined section.</p><p>Now this regex certainly isn’t perfect, you can imagine a scenario that it would miss, for instance if there’s a space between pep and 8 or if it was lowercase, it would miss both of those, so you’d likely need to spend some time refining your regex.  However the point is to illustrate how you can use regex and give a practical example of a case that you might use it in.  So now up to this point we’ve explored three different regex methods with some practical application of how you might use it.  But there are a lot of other regex methods within this repackage.  Few are listed below, so there’s search, match, full match, find itter, and escape.  Even more broadly, the regex that we explored are very, very simple.  They can get very complex.  And the best way to learn it is by defining your own string with the goal of identifying some substring, pull up a regex cheat sheet, and start exploring different patterns to try to identify that substring.</p><h4 id="other-examples-of-regex-methods"><a class="markdownIt-Anchor" href="#other-examples-of-regex-methods"></a> Other examples of regex methods</h4><ul><li>re.search()</li><li>re.match()</li><li>re.fullmatch()</li><li>re.finditer()</li><li>re.escape()</li></ul><h2 id="machine-learning-pipeline"><a class="markdownIt-Anchor" href="#machine-learning-pipeline"></a> Machine Learning Pipeline</h2><p>Up to this point, we’ve learned some basics of NLP and NLTK.  We’ve learned how to read in messy text, and we’ve learned how to use regular expressions to search for and manipulate that text.  Now, we’ll take a step back to understand how this all fits together in the broader machine learning pipeline before we dive into each step individually.  This section is going to introduce some new topics as well and we’ll cover each of these topics later.  This is meant only to provide the proper context for how this all fits together.</p><p>In a typical machine learning text pipeline, you’ll start with some document with raw text in it, like the SMS data set that we’re working with.  It’s important to note that at this stage, the computer has no idea what it’s looking at.  All it sees is a collection of characters.  It doesn’t know the word ham from the word spam.  The characters mean nothing.  It doesn’t even know a space from a number or a letter.  They’re all the same.</p><p>So the first thing we need to do is tokenize our text.  We did this earlier in this chapter by splitting on white space or special characters.  So you would take the sentence, “I am learning NLP,” and it would split into a list with four tokens, I and then am and then learning, and lastly NLP.  So now, instead of just seeing one long string of characters like it was seeing before, now Python will see a list with four distinct tokens, so it knows what to look at.  So now we have a list of tokens, so Python knows what to look at.</p><p>However, some of the words might be a little bit more important than other words.  For instance, the words the, and, of, or, appear very frequently but don’t really offer much information about the sentence itself.  These are what’s called stop words.  We took a quick look at these earlier in this post.  Typically, you will remove these words to allow Python to really focus in on the most pivotal words in our sentence.  So in the example we used previously, instead of a list with I, am, learning, NLP, once you remove stop words, now you’re just left with learning and NLP.  This still gets across the most important point of the sentence, but now you’re only looking at half the amount of tokens.  Also, the process of stemming helps Python realize that words like learn, learned and learning all have basically the same semantic meaning.  You may not think this is a big deal, and in a small sample it’s really not, but when you all of a sudden have a million text messages, and a corpus of 150,000 words, any words that you can remove to allow Python to focus on the most pivotal words can really make a big difference.</p><p>So now Python sees a list of tokens you care about, and the key words that we think are useful for building some kind of machine learning model.  Even though Python now knows what you care about, it still only sees characters.  It doesn’t know what learning or NLP even means.  So we have to convert it to a format that a machine learning algorithm can actually ingest and use to build a model.  This is a process called vectorizing.  It’s basically converting the text to a numeric representation of that text, where you are essentially counting the occurrences of each word in each text message using a matrix with one row per text message and one column per word.</p><p>So that you have this numeric matrix, you can now fit your actual machine learning model by feeding in your vectorized data along with your spam or ham labels.  The model will then learn the relationships between the words and the labels in order to train a model to make predictions on text messages that it has never seen before and determine whether they are spam or not.  There are various types of machine learning models.  It will be up to you to select a few of them to try out.  You’ll tailor your choices based on the type of input data you’re giving it, what you’re trying to predict, how much compute power you have, things like that.  You’ll typically test out a number of what’s called candidate models before selecting which model performs best.  Once you select the best model, you’ll evaluate that on a holdout test set, and this is typically a set of data that you’ll set off to the side in the very beginning for the purpose of testing your final model on it to see how your model will perform on data that it’s never seen or touched before.  If it passes this final test, then you’ll prepare to implement it within whatever framework you’re working with.  In this example, it’s an illustration of a spam filter, trying to filter out whether incoming email is spam or not.</p><h2 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h2><p>In the previous part, we put those together at a conceptual level, laying out what the full machine learning pipeline looks like.  In this part, we’re going to actually write the code to handle to cleaning portion, or the pre-processing as it’s typically referred to, of this machine learning program.  There are four steps below that you’ll see in a lot of text cleaning pipelines: <strong>removing the punctuation, tokenization, removing stop words, and lemmatising or stemming</strong>.  We’re going to focus on the first three steps in this session, then we’ll cover lemmatising and stemming in the next chapter of the post, as those are a little bit more advanced and not implemented in every pipeline.</p><p>The following sample is our target output for all:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># What does the cleaned version look like?</span></span><br><span class="line">data_cleaned = pd.read_csv(<span class="string">"SMSSpamCollection_cleaned.tsv"</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">data_cleaned.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th><th style="text-align:center">body_text_nostop</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">ham</td><td style="text-align:center">I’ve been searching for the right words to thank you for this breather. I promise i wont take yo…</td><td style="text-align:center">[‘ive’, ‘searching’, ‘right’, ‘words’, ‘thank’, ‘breather’, ‘promise’, ‘wont’, ‘take’, ‘help’, '…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive …</td><td style="text-align:center">[‘free’, ‘entry’, ‘2’, ‘wkly’, ‘comp’, ‘win’, ‘fa’, ‘cup’, ‘final’, ‘tkts’, ‘21st’, ‘may’, '2005…</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I don’t think he goes to usf, he lives around here though</td><td style="text-align:center">[‘nah’, ‘dont’, ‘think’, ‘goes’, ‘usf’, ‘lives’, ‘around’, ‘though’]</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me. They treat me like aids patent.</td><td style="text-align:center">[‘even’, ‘brother’, ‘like’, ‘speak’, ‘treat’, ‘like’, ‘aids’, ‘patent’]</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">[‘date’, ‘sunday’]</td></tr></tbody></table><h3 id="removing-punctuation"><a class="markdownIt-Anchor" href="#removing-punctuation"></a> Removing Punctuation</h3><p>Import data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># Set dataframe max coloumn width to 100 characters, and default is 50</span></span><br><span class="line">pd.set_option(<span class="string">'display.max_colwidth'</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read the file with the delimiter of tabs and set header to none</span></span><br><span class="line">data = pd.read_csv(<span class="string">"SMSSpamCollection.tsv"</span>, sep=<span class="string">'\t'</span>, header=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setting the header manually</span></span><br><span class="line">data.columns = [<span class="string">'label'</span>, <span class="string">'body_text'</span>]</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">ham</td><td style="text-align:center">I’ve been searching for the right words to thank you for this breather. I promise i wont take yo…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive …</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I don’t think he goes to usf, he lives around here though</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me. They treat me like aids patent.</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td></tr></tbody></table><p>Import string package and show what punctuation has:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> string</span><br><span class="line"></span><br><span class="line">string.punctuation</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'!"#$%&amp;\'()*+,-./:;&lt;=&gt;?@[\\]^_`&#123;|&#125;~'</span></span><br></pre></td></tr></table></figure><p>This is really helpful to allow Python to identify what we’re looking for.  The reason that we care about this is that periods, parentheses, and other punctuation look like just another character to Python.  But realistically, the period doesn’t really help pull the meaning out of a sentence.  In the following example, for us “I like NLP.”, with a period, is exactly the same as, “I like NLP”.  They mean the same thing to us, but when you give that to Python, Python says those are not equivalent things.  And Python isn’t saying “I like NLP” without a period is different than “I like NLP.”  With a period, in that they’re really close, but one has a period and one doesn’t.  To Python, these might was well be “I like NLP” versus “I hate NLP”.  It knows they’re different without any ability to understand how different they are.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"I like NLP."</span> == <span class="string">"I like NLP"</span></span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><p>There is the function to remove the punctuation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_punctuation</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="comment"># Check if a character is in string punctuationk, if it is not, return this charactor</span></span><br><span class="line">    <span class="comment"># and the join all characters together by using "".join</span></span><br><span class="line">    text_nopunct = <span class="string">""</span>.join(char <span class="keyword">for</span> char <span class="keyword">in</span> text <span class="keyword">if</span> char <span class="keyword">not</span> <span class="keyword">in</span> string.punctuation)</span><br><span class="line">    <span class="keyword">return</span> text_nopunct</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is going to apply our lambda function to each row of body_text</span></span><br><span class="line">data[<span class="string">"body_text_clean"</span>] = data[<span class="string">"body_text"</span>].apply(<span class="keyword">lambda</span> x : remove_punctuation(x))</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th><th style="text-align:center">body_text_nostop</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">ham</td><td style="text-align:center">I’ve been searching for the right words to thank you for this breather. I promise i wont take yo…</td><td style="text-align:center">Ive been searching for the right words to thank you for this breather I promise i wont take your…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive …</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e…</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I don’t think he goes to usf, he lives around here though</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me. They treat me like aids patent.</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL</td></tr></tbody></table><h3 id="tokenisation"><a class="markdownIt-Anchor" href="#tokenisation"></a> Tokenisation</h3><p>As we discussed previously, tokenizing is splitting some string or sentence into a list of words.  We learn that you have to account for extra cases in your strings, like if they’re separated by special characters or multiple spaces.  So we’ll just use what we learned in our lesson about regexes, and combine that with the approach we learned in the last lesson, where we removed punctuation by writing our own function, and then applying it to our data set using a lambda function in order to tokenize our text.</p><p>The following code is going to tokenise text data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenise</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="comment"># The \W+ regex, indicates that it will split wherever it sees one or more non-word characters</span></span><br><span class="line">    tokens = re.split(<span class="string">"\W+"</span>, text)</span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line"></span><br><span class="line"><span class="comment"># Similar to removing punctuation, apply the function to text data as well as lower the case</span></span><br><span class="line"><span class="comment"># because Python is case sensitive</span></span><br><span class="line">data[<span class="string">"body_text_tokenised"</span>] = data[<span class="string">"body_text_clean"</span>].apply(<span class="keyword">lambda</span> x : tokenise(x.lower()))</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th><th style="text-align:center">body_text_clean</th><th style="text-align:center">body_text_tokenised</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">ham</td><td style="text-align:center">I’ve been searching for the right words to thank you for this breather. I promise i wont take yo…</td><td style="text-align:center">Ive been searching for the right words to thank you for this breather I promise i wont take your…</td><td style="text-align:center">[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, …</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive …</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e…</td><td style="text-align:center">[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to…</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I don’t think he goes to usf, he lives around here though</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td><td style="text-align:center">[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me. They treat me like aids patent.</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent</td><td style="text-align:center">[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL</td><td style="text-align:center">[i, have, a, date, on, sunday, with, will]</td></tr></tbody></table><p>Example of case sensitive:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"NLP"</span> == <span class="string">"nlp"</span></span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><h3 id="removing-stop-words"><a class="markdownIt-Anchor" href="#removing-stop-words"></a> Removing Stop Words</h3><p>The last step in cleaning up this data is to remove stopwords.  Now we’ve discussed stopwords previously.  They are commonly-used words like the, but, if, that don’t contribute much to the meaning of a sentence.  So we want to remove them, to limit the number of tokens Python actually has to look at when building our model.  For instance, take the sentence,  I am learning NLP.  After tokenizing, it would have four tokens, I, am, learning, and NLP.  Then after removing stopwords, instead of a list with four tokens, you’re now left with just learning and NLP.  So it gets across the same message, and now, your machine learning model only has to look at half the number of tokens.</p><p>Get all stop words:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line">stopword = nltk.corpus.stopwords.words(<span class="string">"english"</span>)</span><br></pre></td></tr></table></figure><p>Remove all stop words:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_stopwords</span><span class="params">(tokenised_list)</span>:</span></span><br><span class="line">    text = [word <span class="keyword">for</span> word <span class="keyword">in</span> tokenised_list <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopword]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line">data[<span class="string">"body_text_nostop"</span>] = data[<span class="string">"body_text_tokenised"</span>].apply(<span class="keyword">lambda</span> x : remove_stopwords(x))</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th><th style="text-align:center">body_text_clean</th><th style="text-align:center">body_text_tokenised</th><th style="text-align:center">body_text_nostop</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">ham</td><td style="text-align:center">I’ve been searching for the right words to thank you for this breather. I promise i wont take yo…</td><td style="text-align:center">Ive been searching for the right words to thank you for this breather I promise i wont take your…</td><td style="text-align:center">[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, …</td><td style="text-align:center">[ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive …</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e…</td><td style="text-align:center">[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to…</td><td style="text-align:center">[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv…</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I don’t think he goes to usf, he lives around here though</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td><td style="text-align:center">[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td><td style="text-align:center">[nah, dont, think, goes, usf, lives, around, though]</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me. They treat me like aids patent.</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent</td><td style="text-align:center">[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td><td style="text-align:center">[even, brother, like, speak, treat, like, aids, patent]</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL</td><td style="text-align:center">[i, have, a, date, on, sunday, with, will]</td><td style="text-align:center">[date, sunday]</td></tr></tbody></table><p>So now we have a cleaned column that has been tokenised, we’ve removed the punctuation and we’ve removed the stopwords.  So that is a very abbreviated look at what a pre-processing pipeline looks like as you’re preparing to get your raw text into a format that a machine learning model can actually use. In the next chapter, we’ll explore some extra, slightly more advanced cleaning techniques and concepts that we can apply to our text to further help a machine learning model focus on the things that are really important.</p><h1 id="supplemental-data-cleaning"><a class="markdownIt-Anchor" href="#supplemental-data-cleaning"></a> Supplemental Data Cleaning</h1><h2 id="introducting-stemming"><a class="markdownIt-Anchor" href="#introducting-stemming"></a> Introducting Stemming</h2><p>The formal definition of stemming is the process of reducing inflected or derived words to their word stem or root.  More simply put, the process of stemming means often crudely chopping off the end of a word, to leave only the base.  So this means taking words with various suffixes and condensing them under the same root word.  Recall when we removed stop words, it was to reduce the number of words Python has to look at or consider.  Stemming is shooting for the same goal by reducing variations of the same root word.</p><p>Examples:</p><table><thead><tr><th style="text-align:center">before</th><th style="text-align:center">after</th></tr></thead><tbody><tr><td style="text-align:center">Stemming / stemmed</td><td style="text-align:center">Stem</td></tr><tr><td style="text-align:center">Electricity / electrical</td><td style="text-align:center">Electr</td></tr><tr><td style="text-align:center">Berries / berry</td><td style="text-align:center">berri</td></tr><tr><td style="text-align:center">Connection / connected / connective</td><td style="text-align:center">Connect</td></tr></tbody></table><p>So this seems pretty useful, but stemming uses very crude rules, so it isn’t perfect.  For instance, look at meaning and meanness.  These words aren’t really all that closely related, but they’ll be both stripped down to a base of mean.  And thus Python will think that meanness and meaning are the same exact thing.  So stemmers are correct in most cases, but the trade-off with these simple rules is that it won’t always be right.</p><p>So this all seems interesting, but why do we really care about this?  Why does this actually help us for model building?  If Python sees grew, grow, and growing as three separate things, that means it has to keep those three separate words in memory.  Imagine every variation of every root word.  Maybe we have a thousand root words, but in our corpus, we have two thousand total words with every suffix added to the root words.  The alternative in this grew, grow, and growing example is applying the stemmer, and now it only has to know what grow means, as each variation of grow is replaced simply by grow.  So Python has to look at a lot more tokens without a stemmer and it doesn’t know that these separate tokens are even related.  So the benefits of a stemmer is <strong>it reduces the corpus of words the model is exposed to</strong>, so it’s just grow, instead of grew, grow, and growing, and <strong>it explicitly correlates words with similar meaning</strong>.  So Python could learn through the training process that we’ll discuss later, that grow, grew, and growing are similar in meaning, but it also may not, it depends on a lot of different factors.  In this case, we’re not leaving it up to Python.  We’re being explicit by replacing similar words with just one common root word.  There are a number of different types of stemmers that use various algorithms and methods to generate the stemmed version of words.  A few that are included in the NLTK package are the <strong>Porter Stemmer, the Snowball Stemmer, the Lancaster Stemmer, and a Regex-Based Stemmer</strong>. We’ll be focusing on the most popular stemmer in this list, the <strong>Porter Stemmer</strong>.</p><h2 id="using-stemming"><a class="markdownIt-Anchor" href="#using-stemming"></a> Using Stemming</h2><p>To make the use of stemming, there are two stages.  First, we’ll test out the stemmer on specific words to understand how it works.  Then we’ll apply the stemmer on the SMS spam collection data set to further clean up our data.</p><p>Import package:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line">ps = nltk.PorterStemmer()</span><br></pre></td></tr></table></figure><p>First example of using the function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(ps.stem(<span class="string">"grows"</span>))</span><br><span class="line">print(ps.stem(<span class="string">"growing"</span>))</span><br><span class="line">print(ps.stem(<span class="string">"grow"</span>))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grow</span><br><span class="line">grow</span><br><span class="line">grow</span><br></pre></td></tr></table></figure><p>So that reduces them all to the proper root word of grow.  So now these three words can be treated as the same word, rather than Python seeing them as three distinctly different words.</p><p>We showed before how the stemmer isn’t perfect, where it stemmed both meaning and meanness down to mean, even though they don’t represent the same thing.  However, if you look at a different example that could be a little difficult, we’ll do run, running, and runner.  You could see how all three of these might be reduced down to just run. Even though the first two are actions and the last one describes a person.</p><p>Second example of using the function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(ps.stem(<span class="string">"run"</span>))</span><br><span class="line">print(ps.stem(<span class="string">"running"</span>))</span><br><span class="line">print(ps.stem(<span class="string">"runner"</span>))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">run</span><br><span class="line">run</span><br><span class="line">runner</span><br></pre></td></tr></table></figure><p>So the stemmer can actually tell that the first two are different than the last one in some way.  So stemmers certainly aren’t perfect, but they still do a pretty good job of identifying words that have the same meaning.</p><p>Let’s use it for our SMS Spam example!</p><p>Import packages and read the file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line">pd.set_option(<span class="string">'display.max_colwidth'</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">"SMSSpamCollection.tsv"</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">data.columns = [<span class="string">'label'</span>, <span class="string">'body_text'</span>]</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive …</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent.</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">As per your request ‘Melle Melle (Oru Minnaminunginte Nurungu Vettam)’ has been set as your call…</td></tr></tbody></table><p>Clean up text:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = <span class="string">""</span>.join([word <span class="keyword">for</span> word <span class="keyword">in</span> text <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> string.punctuation])</span><br><span class="line">    tokens = re.split(<span class="string">'\W+'</span>, text)</span><br><span class="line">    text = [word <span class="keyword">for</span> word <span class="keyword">in</span> tokens <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line">data[<span class="string">'body_text_nostop'</span>] = data[<span class="string">'body_text'</span>].apply(<span class="keyword">lambda</span> x: clean_text(x.lower()))</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th><th style="text-align:center">body_text_nostop</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive …</td><td style="text-align:center">[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td><td style="text-align:center">[nah, dont, think, goes, usf, lives, around, though]</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent.</td><td style="text-align:center">[even, brother, like, speak, treat, like, aids, patent]</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">[date, sunday]</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">As per your request ‘Melle Melle (Oru Minnaminunginte Nurungu Vettam)’ has been set as your call…</td><td style="text-align:center">[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr…</td></tr></tbody></table><p>We saw that the ps.stem method is what stems each word.  So the column that we’ll be operating on from this data frame is this tokenized list.  So we’ll want to iterate through the list and stem each word and then return the stemmed version back to the list.  So this should be starting to sound familiar at this point.  We’ll again write our own function using ps.stem within list comprehension in order to stem each word.</p><p>The following code is the way to stem the text:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stemming</span><span class="params">(tokenised_text)</span>:</span></span><br><span class="line">    text = [ps.stem(word) <span class="keyword">for</span> word <span class="keyword">in</span> tokenised_text]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line">data[<span class="string">"body_text_stemmed"</span>] = data[<span class="string">"body_text_nostop"</span>].apply(<span class="keyword">lambda</span> x : stemming(x))</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th><th style="text-align:center">body_text_nostop</th><th style="text-align:center">body_text_stemmed</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive …</td><td style="text-align:center">[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv…</td><td style="text-align:center">[free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td><td style="text-align:center">[nah, dont, think, goes, usf, lives, around, though]</td><td style="text-align:center">[nah, dont, think, goe, usf, live, around, though]</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent.</td><td style="text-align:center">[even, brother, like, speak, treat, like, aids, patent]</td><td style="text-align:center">[even, brother, like, speak, treat, like, aid, patent]</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">[date, sunday]</td><td style="text-align:center">[date, sunday]</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">As per your request ‘Melle Melle (Oru Minnaminunginte Nurungu Vettam)’ has been set as your call…</td><td style="text-align:center">[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr…</td><td style="text-align:center">[per, request, mell, mell, oru, minnaminungint, nurungu, vettam, set, callertun, caller, press, …</td></tr></tbody></table><p>Now it’s worth noting that the stemmer won’t do a great job with slang or abbreviations.  So it’s probably not a great fit for a text message data set.  To be noticed that entry is changed to entri with an i so it could also accommodate plural, entries.  Same thing with wkli.  Another one is on the second line, lives is reduced down to live.  So, we know what stemming represents, and how to actually apply it.  Stemming helps us reduce the corpus of words that the models are exposed to, and it explicitly correlates words with similar meaning.</p><h2 id="introducting-lemmatising"><a class="markdownIt-Anchor" href="#introducting-lemmatising"></a> Introducting Lemmatising</h2><p>The formal definition is that it’s the process of grouping together the inflected forms of a word so they can be analyzed as a single term, identified by the word’s lemma.  The lemma is the canonical form of a set of words.  For instance, type, typed, and typing would all be forms of the same lemma.  More simply put, lemmatising is using vocabulary analysis of words to remove inflectional endings and return to the dictionary form of a word.  So again, type, typed, and typing would all be simplified down to type, because that’s the root of the word.  Each variation carries the same meaning just with slightly different tense.  So you might be thinking that that sounds an awful lot like stemming, and you wouldn’t be wrong.  They are aiming to accomplish the same thing, but they are doing it in just slightly different ways.  And in practical terms, there’s an accuracy and speed trade-off that you’re making when you opt for one over the other.</p><p>The goal of both is to condense derived words down into their base form, to reduce the corpus of words that the model’s exposed to, and to explicitly correlate words with similar meaning.  The difference is that stemming takes a more crude approach by just chopping off the ending of a word using heuristics, without any understanding of the context in which a word is used.  Because of that, stemming may or may not return an actual word in the dictionary.  And it’s usually less accurate, but the benefit is that it’s faster because the rules are quite simple.  lemmatising leverages more informed analysis to create groups of words with similar meaning based on the context around the word, part of speech, and other factors.  lemmatisers will always return a dictionary word.  And because of the additional context it’s considered, this is typically more accurate.  But the downside is that it may be more computationally expensive.  So this is a very brief introduction into lemmatising.</p><h2 id="using-lemmatising"><a class="markdownIt-Anchor" href="#using-lemmatising"></a> Using Lemmatising</h2><p>To make the use of Lemmatising, there are two stages.  First, we’re going to test out the lemmatiser on specific words to understand how it works and then we’ll apply it on the SMS Spam Collection Data Set to further clean it up.  So the same process that we saw on the stemming notebook.  Just like we saw with stemmers, there are a few different lemmatisers as well that handle words in slightly different ways.  So we’re going to use the WordNet lemmatiser. This is probably the most popular lemmatiser.  WordNet is a collection of nouns, verbs, adjective and adverbs that are grouped together in sets of synonyms, each expressing a distinct concept.  This lemmatiser runs off of this corpus of synonyms, so given a word, it will track that word to its synonyms, and then the distinct concept that that group of words represents.</p><h3 id="test-out-wordnet-lemmatiser-read-more-about-wordnet-here"><a class="markdownIt-Anchor" href="#test-out-wordnet-lemmatiser-read-more-about-wordnet-here"></a> Test out WordNet lemmatiser (read more about WordNet <a href="https://wordnet.princeton.edu/" target="_blank" rel="noopener">here</a>)</h3><p>Import the nltk package and apply both lemmatiser and stemmer function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line">wn = nltk.WordNetlemmatiser()</span><br><span class="line">ps = nltk.PorterStemmer()</span><br></pre></td></tr></table></figure><h3 id="comparation-between-lemmatiser-and-stemmer"><a class="markdownIt-Anchor" href="#comparation-between-lemmatiser-and-stemmer"></a> Comparation between Lemmatiser and Stemmer</h3><h4 id="first-example"><a class="markdownIt-Anchor" href="#first-example"></a> First Example</h4><p>Stemmer:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(ps.stem(<span class="string">"meanness"</span>))</span><br><span class="line">print(ps.stem(<span class="string">"meaning"</span>))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mean</span><br><span class="line">mean</span><br></pre></td></tr></table></figure><p>As we have mentioned that, meanness and meaning are different but stemmer still cuts off and return root words for both words.</p><p>Lemmartiser:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(wn.lemmatise(<span class="string">"meanness"</span>))</span><br><span class="line">print(wn.lemmatise(<span class="string">"meaning"</span>))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">meanness</span><br><span class="line">meaning</span><br></pre></td></tr></table></figure><p>Two things need to be highlighted here.  First, stemming uses the algorithmic approach so it’s only concerned with the string that it’s given, and it will essentially chop off the suffix.  lemmatising is a little bit more complex in that it searches the corpus to find related words and condense it down to the core concept.  The problem is that if this word isn’t in the corpus, then it will just return the original word, so that’s what’s happening in this example.  With that said, not condensing it in this case is probably better than incorrectly stemming it using the Porter stemmer.</p><h4 id="second-example"><a class="markdownIt-Anchor" href="#second-example"></a> Second Example</h4><p>Stemmer:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(ps.stem(<span class="string">"goose"</span>))</span><br><span class="line">print(ps.stem(<span class="string">"geese"</span>))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">goos</span><br><span class="line">gees</span><br></pre></td></tr></table></figure><p>You can see that the stemmer doesn’t quite know what to do here with goose and geese so it returns two different root words. So again, Python will still view goose and geese as two different things even if you use the stemmer.</p><p>Lemmartiser:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(wn.lemmatise(<span class="string">"goose"</span>))</span><br><span class="line">print(wn.lemmatise(<span class="string">"geese"</span>))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">goose</span><br><span class="line">goose</span><br></pre></td></tr></table></figure><p>You can see that the lemmatiser correctly maps both of these back to goose.  Python will then be able to now realize that these are the same words, so a lemmatiser can be quite powerful in some relatively complex situations.</p><h3 id="apply-lammatiser-to-sms-spam-collection-data"><a class="markdownIt-Anchor" href="#apply-lammatiser-to-sms-spam-collection-data"></a> Apply lammatiser to SMS Spam Collection Data</h3><p>Read the text file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line">pd.set_option(<span class="string">'display.max_colwidth'</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">"SMSSpamCollection.tsv"</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">data.columns = [<span class="string">'label'</span>, <span class="string">'body_text'</span>]</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive …</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent.</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">As per your request ‘Melle Melle (Oru Minnaminunginte Nurungu Vettam)’ has been set as your call…</td></tr></tbody></table><p>Clean up text:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = <span class="string">""</span>.join([word <span class="keyword">for</span> word <span class="keyword">in</span> text <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> string.punctuation])</span><br><span class="line">    tokens = re.split(<span class="string">'\W+'</span>, text)</span><br><span class="line">    text = [word <span class="keyword">for</span> word <span class="keyword">in</span> tokens <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line">data[<span class="string">'body_text_nostop'</span>] = data[<span class="string">'body_text'</span>].apply(<span class="keyword">lambda</span> x: clean_text(x.lower()))</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th><th style="text-align:center">body_text_nostop</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive …</td><td style="text-align:center">[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td><td style="text-align:center">[nah, dont, think, goes, usf, lives, around, though]</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent.</td><td style="text-align:center">[even, brother, like, speak, treat, like, aids, patent]</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">[date, sunday]</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">As per your request ‘Melle Melle (Oru Minnaminunginte Nurungu Vettam)’ has been set as your call…</td><td style="text-align:center">[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr…</td></tr></tbody></table><p>Lemmatise text using body_text_nostop data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lemmatising</span><span class="params">(tokenised_text)</span>:</span></span><br><span class="line">    text = [wn.lemmatise(word) <span class="keyword">for</span> word <span class="keyword">in</span> tokenised_text]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line">data[<span class="string">"body_text_lammatised"</span>] = data[<span class="string">"body_text_nostop"</span>].apply(<span class="keyword">lambda</span> x : lemmatising(x))</span><br><span class="line"></span><br><span class="line">data.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">label</th><th style="text-align:center">body_text</th><th style="text-align:center">body_text_nostop</th><th style="text-align:center">body_text_lammatised</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">spam</td><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive …</td><td style="text-align:center">[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv…</td><td style="text-align:center">[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv…</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">ham</td><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td><td style="text-align:center">[nah, dont, think, goes, usf, lives, around, though]</td><td style="text-align:center">[nah, dont, think, go, usf, life, around, though]</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">ham</td><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent.</td><td style="text-align:center">[even, brother, like, speak, treat, like, aids, patent]</td><td style="text-align:center">[even, brother, like, speak, treat, like, aid, patent]</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">ham</td><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">[date, sunday]</td><td style="text-align:center">[date, sunday]</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">ham</td><td style="text-align:center">As per your request ‘Melle Melle (Oru Minnaminunginte Nurungu Vettam)’ has been set as your call…</td><td style="text-align:center">[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, callers, pr…</td><td style="text-align:center">[per, request, melle, melle, oru, minnaminunginte, nurungu, vettam, set, callertune, caller, pre…</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">spam</td><td style="text-align:center">WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To c…</td><td style="text-align:center">[winner, valued, network, customer, selected, receivea, 900, prize, reward, claim, call, 0906170…</td><td style="text-align:center">[winner, valued, network, customer, selected, receivea, 900, prize, reward, claim, call, 0906170…</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">spam</td><td style="text-align:center">Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with came…</td><td style="text-align:center">[mobile, 11, months, u, r, entitled, update, latest, colour, mobiles, camera, free, call, mobile…</td><td style="text-align:center">[mobile, 11, month, u, r, entitled, update, latest, colour, mobile, camera, free, call, mobile, …</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">ham</td><td style="text-align:center">I’m gonna be home soon and i don’t want to talk about this stuff anymore tonight, k? I’ve cried …</td><td style="text-align:center">[im, gonna, home, soon, dont, want, talk, stuff, anymore, tonight, k, ive, cried, enough, today]</td><td style="text-align:center">[im, gonna, home, soon, dont, want, talk, stuff, anymore, tonight, k, ive, cried, enough, today]</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">spam</td><td style="text-align:center">SIX chances to win CASH! From 100 to 20,000 pounds txt&gt; CSH11 and send to 87575. Cost 150p/day, …</td><td style="text-align:center">[six, chances, win, cash, 100, 20000, pounds, txt, csh11, send, 87575, cost, 150pday, 6days, 16,…</td><td style="text-align:center">[six, chance, win, cash, 100, 20000, pound, txt, csh11, send, 87575, cost, 150pday, 6days, 16, t…</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">spam</td><td style="text-align:center">URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM…</td><td style="text-align:center">[urgent, 1, week, free, membership, 100000, prize, jackpot, txt, word, claim, 81010, tc, wwwdbuk…</td><td style="text-align:center">[urgent, 1, week, free, membership, 100000, prize, jackpot, txt, word, claim, 81010, tc, wwwdbuk…</td></tr></tbody></table><p>Just like the stemmer, the lemmatiser won’t do particularly well with slang or abbreviations, so it’s not ideal for this data set.  It might be much more effective if it was used on a collection of book reports or journal articles.  There are a couple things that the lemmatiser was able to impact.  It transitioned this lives down into life, and it also transitioned mobiles into mobile, and so you’ll notice that these aren’t super interesting examples necessarily, but as you saw above, the lemmatiser can do some relatively sophisticated things, at least more sophisticated than the stemmer.  Now you’ve learned what lemmatising is, and how to actually apply it, so both stemming and lemmatising helps us reduce the corpus of words that the model is exposed to, and it explicitly correlates words with similar meaning.  The lemmatiser is typically more accurate than the stemmer but the trade-off is that it takes a little bit longer to run.  Based on your machine learning pipeline, if the lemmatiser is going to be a bottleneck, then you may opt for the more simple stemmer.</p><h1 id="vectorising-raw-data"><a class="markdownIt-Anchor" href="#vectorising-raw-data"></a> Vectorising Raw Data</h1><h2 id="introducing-vectorising"><a class="markdownIt-Anchor" href="#introducing-vectorising"></a> Introducing Vectorising</h2><p>The process that we use to convert text to a form that Python and a machine learning model can understand is called vectorizing.  This is defined as the process of encoding text as integers to create feature vectors.  Now if you don’t have much machine learning experience, you may be wondering what a feature vector is.  A feature vector is an n-dimensional vector of numerical features that represent some object.  So in our context, that means we’ll be taking an individual text message and converting it to a numeric vector that represents that text message.</p><p>Based on the following example, what we’re doing when we vectorize text is we’re taking this dataset that has one line per document with the cell entry as the actual text message and then we’re converting it to a matrix that still has one line per document, but then you have every word used across all documents as the columns of your matrix.  And then within each cell is counting how many times that certain word appeared in that document.  And this is called your document term matrix.  We’ll be referring to this term quite a bit.  Then once we have this numeric representation of each text message, then we can carry on down the pipeline and fit and train a model.</p><table><thead><tr><th style="text-align:center">body_text</th><th style="text-align:center">call</th><th style="text-align:center">claim</th><th style="text-align:center">free</th><th style="text-align:center">txt</th><th style="text-align:center">label</th></tr></thead><tbody><tr><td style="text-align:center">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive …</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">spam</td></tr><tr><td style="text-align:center">Nah I dont think he goes to usf he lives around here though</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">Even my brother is not like to speak with me They treat me like aids patent.</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">As per your request ‘Melle Melle (Oru Minnaminunginte Nurungu Vettam)’ has been set as your call…</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To c…</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">spam</td></tr><tr><td style="text-align:center">Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with came…</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">spam</td></tr><tr><td style="text-align:center">I’m gonna be home soon and i don’t want to talk about this stuff anymore tonight, k? I’ve cried …</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">SIX chances to win CASH! From 100 to 20,000 pounds txt&gt; CSH11 and send to 87575. Cost 150p/day, …</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">spam</td></tr><tr><td style="text-align:center">URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM…</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">spam</td></tr></tbody></table><p>To understand the motivation behind this process, as we mentioned previously that when looking at a word, Python only sees characters.  So we need to convert this into a format that Python can understand in order for our machine learning models to start to learn what certain words indicate about the overall sentence or document or label that we’re trying to predict.  So we vectorize this text to create a matrix that only has numeric entries.  So in our case, counting how many times each word appears in each text message.  The machine learning algorithm understands these counts.  So if it sees a one or a two or a three in a cell, then that model can start to correlate that with whatever we’re trying to predict.  In our case, that’s spam.  To roughly understand then, what the words, sentences, and documents represent.  So in our context, this means it can use how frequently these certain words appear to determine whether the individual text message is spam or not.</p><p>Let’s classify the following document term matrix each as either spam or ham.  We’re just focusing on two words here used in text messages, offer and lol, along with the label of either spam or ham.  So that’s what this looks like after vectorizing.  Now how does a machine learning model use this information to learn what these words mean?  It was mentioned before that by looking at the counts in the cells, that it can start to correlate which words happen in combination with certain labels.</p><p>Original:</p><table><thead><tr><th style="text-align:center">id</th><th style="text-align:center">offer</th><th style="text-align:center">lol</th><th style="text-align:center">label</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">4</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">0</td><td style="text-align:center">spam</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">spam</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">spam</td></tr></tbody></table><p>So let’s isolate just the non-spam messages in following table. You can start to notice that offer occurs very infrequently, but lol occurs in a lot of these non-spam text messages.  From the numbers here, the model could pretty easily pick up on the fact that lol occurs quite frequently with non-spam text messages and offer occurs very infrequently.  You could see how this would allow a model to start to learn how to predict when a text is spam or not, based just on the text body.</p><p>Filtered ham:</p><table><thead><tr><th style="text-align:center">id</th><th style="text-align:center">offer</th><th style="text-align:center">lol</th><th style="text-align:center">label</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">4</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">ham</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><p>So now, let’s do the same thing, but we’ll jump over to the spam messages in the following table. You can pretty quickly notice that it’s the opposite.  Offer occurs quite frequently, while lol occurs quite infrequently.  So the model would pick up on the fact that offer occurs quite frequently in spam messages and lol occurs quite infrequently.</p><p>Filtered spam:</p><table><thead><tr><th style="text-align:center">id</th><th style="text-align:center">offer</th><th style="text-align:center">lol</th><th style="text-align:center">label</th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">0</td><td style="text-align:center">spam</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">spam</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">spam</td></tr></tbody></table><p>So now, only considering these two words, the model has learned that offer occurs frequently with spam and infrequently with non-spam, while lol occurs frequently with non-spam and infrequently with spam.  So you could see how maybe with even just these two words, the model could start making ham or spam predictions about new text messages based only on the number of times these two words occur.  With that said, this is an extremely simple and exaggerated example for the purpose of illustration.  In reality, the model would need to learn the relationships of much more than two words to make an accurate prediction. But this example was meant to show how vectorizing helps the model roughly learn what words correlate with which labels.</p><p>So far, the post been talking about the entry of each cell in the document term matrix containing the count of how many times a given word appears in that text message, but that’s only one method of vectorization.  And that’s called, not surprisingly, count vectorization.  There are two other variations of count vectorization called N-grams and term frequency - inverse document frequency, which is often referred to as TF-IDF.  We’re going to cover each of these three methods of vectorization in more detail.</p><p>All three of these methods will generate very similar document-term matrices where there’s one line per document, or text message in our case, and then the columns will represent each word or potentially a combination of words. The main difference between the three is what’s in the actual cells of the matrix. So we’ll start with count vectorization.</p><h2 id="count-vectorisation"><a class="markdownIt-Anchor" href="#count-vectorisation"></a> Count Vectorisation</h2><p>Count vectorization creates the document-term matrix and then simply counts the number of times each word appears in that given document, or text message in our case, and that’s what’s stored in the given cell, so it’s pretty straight forward.</p><p>We’re going to use our SMSSpamCollection dataset, and then we’ll build a function to clean it up.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">pd.set_option(<span class="string">'display.max_colwidth'</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br><span class="line">ps = nltk.PorterStemmer()</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">"SMSSpamCollection.tsv"</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">data.columns = [<span class="string">'label'</span>, <span class="string">'body_text'</span>]</span><br></pre></td></tr></table></figure><p>Create function to remove punctuation, tokenize, remove stopwords, and stem:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = <span class="string">""</span>.join([word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> text <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> string.punctuation])</span><br><span class="line">    tokens = re.split(<span class="string">'\W+'</span>, text)</span><br><span class="line">    text = [ps.stem(word) <span class="keyword">for</span> word <span class="keyword">in</span> tokens <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line">    <span class="keyword">return</span> text</span><br></pre></td></tr></table></figure><p>The difference here is, we’re not going to use a lambda function to apply it to our data, like we have in the past. The CountVectorizer actually allows you to pass in a function to clean and tokenize your data.</p><p>Apply CountVectorizer:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># To allow us passing in the function that we created to clean up the text</span></span><br><span class="line"><span class="comment"># and it'll apply that function all at the same time that it's vectorizing the text.</span></span><br><span class="line">count_vect = CountVectorizer(analyzer = clean_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># If we only fit it, it won't actually do anything to our data.</span></span><br><span class="line"><span class="comment"># It'll just train the vectorizer object to learn what words are in the corpus.</span></span><br><span class="line"><span class="comment"># So if we want to actually fit it, and then transform our data, in other words,</span></span><br><span class="line"><span class="comment"># if we want to fit the vectorizer,</span></span><br><span class="line"><span class="comment"># and then actually vectorize our data and turn them into feature vectors,</span></span><br><span class="line"><span class="comment"># then we'll need to call fit_transform, and that'll actually do the fitting and transform our data.</span></span><br><span class="line">X_counts = count_vect.fit_transform(data[<span class="string">"body_text"</span>])</span><br><span class="line"></span><br><span class="line">print(X_counts.shape)</span><br><span class="line">print(count_vect.get_feature_names())</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">5567</span>, <span class="number">8104</span>)</span><br><span class="line">[<span class="string">''</span>, <span class="string">'0'</span>, <span class="string">'008704050406'</span>, <span class="string">'0089mi'</span>, <span class="string">'0121'</span>, <span class="string">'01223585236'</span>, <span class="string">'01223585334'</span>, <span class="string">'0125698789'</span>, <span class="string">'02'</span>, <span class="string">'020603'</span>, <span class="string">'0207'</span>, <span class="string">'02070836089'</span>, <span class="string">'02072069400'</span>, <span class="string">'02073162414'</span>, <span class="string">'02085076972'</span>, <span class="string">'020903'</span>, <span class="string">'021'</span>, <span class="string">'050703'</span>, <span class="string">'0578'</span>, <span class="string">'06'</span>, <span class="string">'060505'</span>, <span class="string">'061104'</span>, <span class="string">'07008009200'</span>, <span class="string">'07046744435'</span>, <span class="string">'07090201529'</span>, <span class="string">'07090298926'</span>, <span class="string">'07099833605'</span>, <span class="string">'071104'</span>, <span class="string">'07123456789'</span>, <span class="string">'0721072'</span>, <span class="string">'07732584351'</span>, <span class="string">'07734396839'</span>, <span class="string">'07742676969'</span>, <span class="string">'07753741225'</span>, <span class="string">'0776xxxxxxx'</span>, <span class="string">'07786200117'</span>, <span class="string">'077xxx'</span>, <span class="string">'078'</span>, <span class="string">'07801543489'</span>, <span class="string">'07808'</span>, <span class="string">'07808247860'</span>, <span class="string">'07808726822'</span>, <span class="string">'07815296484'</span>, <span class="string">'07821230901'</span>, <span class="string">'0784987'</span>, <span class="string">'0789xxxxxxx'</span>, <span class="string">'0794674629107880867867'</span>, <span class="string">'0796xxxxxx'</span>, <span class="string">'07973788240'</span>, <span class="string">'07xxxxxxxxx'</span>, <span class="string">'0800'</span>, <span class="string">'08000407165'</span>, <span class="string">'08000776320'</span>, <span class="string">'08000839402'</span>, <span class="string">'08000930705'</span>, <span class="string">'08000938767'</span>, <span class="string">'08001950382'</span>...]</span><br></pre></td></tr></table></figure><p>This tell us there are 5567 text messages, and across those 5567 text messages, there are 8104 unique words, which means, our document-term matrix has 5567 rows and 8104 columns, and then the get_feature_names, basically means, here are the names of the columns of our document-term matrix.</p><p>Smaller example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data_sample = data[<span class="number">0</span>:<span class="number">20</span>]</span><br><span class="line"></span><br><span class="line">count_vect_sample = CountVectorizer(analyzer = clean_text)</span><br><span class="line">X_counts_sample = count_vect_sample.fit_transform(data_sample[<span class="string">"body_text"</span>])</span><br><span class="line"></span><br><span class="line">print(X_counts_sample.shape)</span><br><span class="line">print(count_vect_sample.get_feature_names())</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">20</span>, <span class="number">192</span>)</span><br><span class="line">[<span class="string">'08002986030'</span>, <span class="string">'08452810075over18'</span>, <span class="string">'09061701461'</span>, <span class="string">'1'</span>, <span class="string">'100'</span>, <span class="string">'100000'</span>, <span class="string">'11'</span>, <span class="string">'12'</span>, <span class="string">'150pday'</span>, <span class="string">'16'</span>, <span class="string">'2'</span>, <span class="string">'20000'</span>, <span class="string">'2005'</span>, <span class="string">'21st'</span>, <span class="string">'3'</span>, <span class="string">'4'</span>, <span class="string">'4403ldnw1a7rw18'</span>, <span class="string">'4txtú120'</span>, <span class="string">'6day'</span>, <span class="string">'81010'</span>, <span class="string">'87077'</span>, <span class="string">'87121'</span>, <span class="string">'87575'</span>, <span class="string">'9'</span>, <span class="string">'900'</span>, <span class="string">'aft'</span>, <span class="string">'aid'</span>, <span class="string">'alreadi'</span>, <span class="string">'alright'</span>, <span class="string">'anymor'</span>, <span class="string">'appli'</span>, <span class="string">'ard'</span>, <span class="string">'around'</span>, <span class="string">'b'</span>, <span class="string">'brother'</span>, <span class="string">'call'</span>, <span class="string">'caller'</span>, <span class="string">'callertun'</span>, <span class="string">'camera'</span>, <span class="string">'cash'</span>, <span class="string">'chanc'</span>, <span class="string">'claim'</span>, <span class="string">'click'</span>, <span class="string">'co'</span>, <span class="string">'code'</span>, <span class="string">'colour'</span>, <span class="string">'comin'</span>, <span class="string">'comp'</span>, <span class="string">'copi'</span>, <span class="string">'cost'</span>, <span class="string">'credit'</span>, <span class="string">'cri'</span>, <span class="string">'csh11'</span>, <span class="string">'cup'</span>, <span class="string">'custom'</span>, <span class="string">'da'</span>, <span class="string">'date'</span>, <span class="string">'dont'</span>, <span class="string">'eg'</span>, <span class="string">'eh'</span>, <span class="string">'england'</span>, <span class="string">'enough'</span>, <span class="string">'entitl'</span>, <span class="string">'entri'</span>, <span class="string">'even'</span>, <span class="string">'fa'</span>, <span class="string">'feel'</span>, <span class="string">'ffffffffff'</span>, <span class="string">'final'</span>, <span class="string">'fine'</span>, <span class="string">'finish'</span>, <span class="string">'first'</span>, <span class="string">'free'</span>, <span class="string">'friend'</span>, <span class="string">'go'</span>, <span class="string">'goalsteam'</span>, <span class="string">'goe'</span>, <span class="string">'gonna'</span>, <span class="string">'gota'</span>, <span class="string">'ha'</span>, <span class="string">'hl'</span>, <span class="string">'home'</span>, <span class="string">'hour'</span>, <span class="string">'httpwap'</span>, <span class="string">'im'</span>, <span class="string">'info'</span>, <span class="string">'ive'</span>, <span class="string">'jackpot'</span>, <span class="string">'joke'</span>, <span class="string">'k'</span>, <span class="string">'kim'</span>, <span class="string">'kl341'</span>, <span class="string">'lar'</span>, <span class="string">'latest'</span>, <span class="string">'lccltd'</span>, <span class="string">'like'</span>, <span class="string">'link'</span>, <span class="string">'live'</span>, <span class="string">'lor'</span>, <span class="string">'lunch'</span>, <span class="string">'macedonia'</span>, <span class="string">'make'</span>, <span class="string">'may'</span>, <span class="string">'meet'</span>, <span class="string">'mell'</span>, <span class="string">'membership'</span>, <span class="string">'messag'</span>, <span class="string">'minnaminungint'</span>, <span class="string">'miss'</span>, <span class="string">'mobil'</span>, <span class="string">'month'</span>, <span class="string">'nah'</span>, <span class="string">'name'</span>, <span class="string">'nation'</span>, <span class="string">'naughti'</span>, <span class="string">'network'</span>, <span class="string">'news'</span>, <span class="string">'next'</span>, <span class="string">'nurungu'</span>, <span class="string">'oh'</span>, <span class="string">'oru'</span>, <span class="string">'patent'</span>, <span class="string">'pay'</span>, <span class="string">'per'</span>, <span class="string">'pobox'</span>, <span class="string">'poboxox36504w45wq'</span>, <span class="string">'pound'</span>, <span class="string">'press'</span>, <span class="string">'prize'</span>, <span class="string">'questionstd'</span>, <span class="string">'r'</span>, <span class="string">'ratetc'</span>, <span class="string">'receiv'</span>, <span class="string">'receivea'</span>, <span class="string">'rememb'</span>, <span class="string">'repli'</span>, <span class="string">'request'</span>, <span class="string">'reward'</span>, <span class="string">'scotland'</span>, <span class="string">'select'</span>, <span class="string">'send'</span>, <span class="string">'serious'</span>, <span class="string">'set'</span>, <span class="string">'six'</span>, <span class="string">'smth'</span>, <span class="string">'soon'</span>, <span class="string">'sooner'</span>, <span class="string">'speak'</span>, <span class="string">'spell'</span>, <span class="string">'stock'</span>, <span class="string">'str'</span>, <span class="string">'stuff'</span>, <span class="string">'sunday'</span>, <span class="string">'talk'</span>, <span class="string">'tc'</span>, <span class="string">'team'</span>, <span class="string">'text'</span>, <span class="string">'think'</span>, <span class="string">'though'</span>, <span class="string">'tkt'</span>, <span class="string">'today'</span>, <span class="string">'tonight'</span>, <span class="string">'treat'</span>, <span class="string">'tri'</span>, <span class="string">'trywal'</span>, <span class="string">'tsandc'</span>, <span class="string">'txt'</span>, <span class="string">'u'</span>, <span class="string">'updat'</span>, <span class="string">'ur'</span>, <span class="string">'urgent'</span>, <span class="string">'use'</span>, <span class="string">'usf'</span>, <span class="string">'v'</span>, <span class="string">'valid'</span>, <span class="string">'valu'</span>, <span class="string">'vettam'</span>, <span class="string">'want'</span>, <span class="string">'wap'</span>, <span class="string">'watch'</span>, <span class="string">'way'</span>, <span class="string">'week'</span>, <span class="string">'wet'</span>, <span class="string">'win'</span>, <span class="string">'winner'</span>, <span class="string">'wkli'</span>, <span class="string">'word'</span>, <span class="string">'wwwdbuknet'</span>, <span class="string">'xxxmobilemovieclub'</span>, <span class="string">'xxxmobilemovieclubcomnqjkgighjjgcbl'</span>, <span class="string">'ye'</span>, <span class="string">'ü'</span>]</span><br></pre></td></tr></table></figure><p>Instead of 5,567 by 8,104, our matrix is just 20 rows by 192 columns, and here are the new feature names.  So there’s some numbers in there, but you can also see around, brother, call, caller.</p><p>One thing to be noted is that the raw data output of the CountVectorizer, is what’s called a Sparse Matrix.  So what is a Sparse Matrix?  when you have a matrix in which a very high percent of the entries are zero, as we do in this case, instead of storing all these zeros in the full matrix, which would make it extremely inefficient, it’ll just be converted to only storing the locations and the values of the non-zero elements, which is much more efficient for storage.</p><p>So if we just try and print out this X_counts_sample, you would’ve previously expected it just to give us our matrix, but instead, it’ll just say this is a sparse matrix object with 218 stored elements in the following example.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_counts_sample</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="number">20</span>x192 sparse matrix of type <span class="string">'&lt;class '</span>numpy.int64<span class="string">'&gt;'</span></span><br><span class="line"><span class="keyword">with</span> <span class="number">218</span> stored elements <span class="keyword">in</span> Compressed Sparse Row format&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_counts_df = pd.DataFrame(X_counts_sample.toarray())</span><br><span class="line">X_counts_df</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">0</th><th style="text-align:right">1</th><th style="text-align:right">2</th><th style="text-align:right">3</th><th style="text-align:right">4</th><th style="text-align:right">5</th><th style="text-align:right">6</th><th style="text-align:right">7</th><th style="text-align:right">8</th><th style="text-align:right">9</th><th style="text-align:right">…</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">6</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">7</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">8</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">9</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">10</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">11</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">12</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">13</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">14</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">15</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">16</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">17</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">18</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr><tr><td style="text-align:right">19</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">…</td></tr></tbody></table><p>20 rows × 192 columns</p><p>You’ll notice that the column names don’t contain the word they actually represent. They’re just numbered from zero to 191. Now again, for Python, this doesn’t really matter because it doesn’t know the difference between a column name of 5, and a column name of text. So it’s just going to learn from the entries in that column, and its relationship with our label, to figure out how it can contribute to the model.</p><p>To be able to see what words those columns actually represent:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_counts_df.columns = count_vect_sample.get_feature_names()</span><br><span class="line">X_counts_df</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">…</th><th style="text-align:right">want</th><th style="text-align:right">wap</th><th style="text-align:right">watch</th><th style="text-align:right">way</th><th style="text-align:right">week</th><th style="text-align:right">wet</th><th style="text-align:right">win</th><th style="text-align:right">winner</th><th style="text-align:right">wkli</th><th style="text-align:right">word</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">6</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">7</td><td style="text-align:right">…</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">8</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">9</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td></tr><tr><td style="text-align:right">10</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">11</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">12</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">13</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">2</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">14</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">15</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">16</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">17</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">18</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">19</td><td style="text-align:right">…</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr></tbody></table><p>20 rows × 192 columns</p><p>Now you’ll see this is exactly the same data frame, now we just have the actual column names here.</p><h2 id="n-gram-vectorising"><a class="markdownIt-Anchor" href="#n-gram-vectorising"></a> N-gram Vectorising</h2><p>Creates a document-term matrix where counts still occupy the cell but instead of the columns representing single terms, they represent all combinations of adjacent words of length n in your text.</p><p>“NLP is an interesting topic”</p><table><thead><tr><th>n</th><th>Name</th><th>Tokens</th></tr></thead><tbody><tr><td>2</td><td>bigram</td><td>[“nlp is”, “is an”, “an interesting”, “interesting topic”]</td></tr><tr><td>3</td><td>trigram</td><td>[“nlp is an”, “is an interesting”, “an interesting topic”]</td></tr><tr><td>4</td><td>four-gram</td><td>[“nlp is an interesting”, “is an interesting topic”]</td></tr></tbody></table><p>The n-grams process creates a document-term matrix like we saw before.  Now we still have one row per text message and we still have counts that occupy the individual cells but instead of the columns representing single terms like we saw in the previous method, now they represent all combinations of adjacent words of length and in your text.  As the above example, let’s use the string NLP is an interesting topic.  This table shows how that would break down.  In n-grams if n equals two then that’s called the bigram and it’ll pull all combinations of two adjacent words in our string.  In NLP is an interesting topic, it will pull out four tokens, NLP is, is an, an interesting, interesting topic.  When n equals three that’s called trigrams.  It’ll pull all combinations of three adjacent words in our string.  We’ll create three tokens, NLP is an, is an interesting, and an interesting topic.  Again, when n equals four, that’s called a four-gram.  It’ll pull all combinations of four adjacent words in our string as you see here with these two tokens.  You can make n as large or as small as you’d like.  You could think of count vectorization as n-grams with n equal a two.  It’ll just pull out the unigrams.  When you use n-grams there’s usually an optimal n value or range that will yield the best performance.  Generally you’ll tune this value to see what generates the best model.  The value here is that you get a little more context around your words.  Rather than only seeing one word at a time, you’ll see two or three or four.  Just to tie this back to something that we talked about earlier, NLP in everyday life, Google’s auto complete uses an n-grams like approach.  If you type natural language into Google, it knows that a very regularly used trigram starting with natural language is natural language processing.  It might suggest that as a full phrase that you’d like to search for.</p><p>Read the data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">pd.set_option(<span class="string">'display.max_colwidth'</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</span><br><span class="line">ps = nltk.PorterStemmer()</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">"SMSSpamCollection.tsv"</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">data.columns = [<span class="string">'label'</span>, <span class="string">'body_text'</span>]</span><br></pre></td></tr></table></figure><p>Create function to remove punctuation, tokenize, remove stopwords, and stem:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = <span class="string">""</span>.join([word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> text <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> string.punctuation])</span><br><span class="line">    tokens = re.split(<span class="string">'\W+'</span>, text)</span><br><span class="line">    text = <span class="string">" "</span>.join([ps.stem(word) <span class="keyword">for</span> word <span class="keyword">in</span> tokens <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords])</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line">data[<span class="string">'cleaned_text'</span>] = data[<span class="string">'body_text'</span>].apply(<span class="keyword">lambda</span> x: clean_text(x))</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:right"></th><th style="text-align:left">label</th><th style="text-align:left">body_text</th><th style="text-align:left">cleaned_text</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:left">spam</td><td style="text-align:left">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C’s apply 08452810075over18’s</td><td style="text-align:left">free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri questionstd txt ratetc appli 08452810075over18</td></tr><tr><td style="text-align:right">1</td><td style="text-align:left">ham</td><td style="text-align:left">Nah I don’t think he goes to usf, he lives around here though</td><td style="text-align:left">nah dont think goe usf live around though</td></tr><tr><td style="text-align:right">2</td><td style="text-align:left">ham</td><td style="text-align:left">Even my brother is not like to speak with me. They treat me like aids patent.</td><td style="text-align:left">even brother like speak treat like aid patent</td></tr><tr><td style="text-align:right">3</td><td style="text-align:left">ham</td><td style="text-align:left">I HAVE A DATE ON SUNDAY WITH WILL!!</td><td style="text-align:left">date sunday</td></tr><tr><td style="text-align:right">4</td><td style="text-align:left">ham</td><td style="text-align:left">As per your request ‘Melle Melle (Oru Minnaminunginte Nurungu Vettam)’ has been set as your callertune for all Callers. Press *9 to copy your friends Callertune</td><td style="text-align:left">per request mell mell oru minnaminungint nurungu vettam set callertun caller press 9 copi friend callertun</td></tr></tbody></table><p>Apply CountVectorizer with N-Grams:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="comment"># Only search for bigram (2, 2)</span></span><br><span class="line"><span class="comment"># if search both unigram and bigram, do (1, 2)</span></span><br><span class="line">ngram_vect = CountVectorizer(ngram_range = (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">X_counts = ngram_vect.fit_transform(data[<span class="string">"cleaned_text"</span>])</span><br><span class="line">print(X_counts.shape)</span><br><span class="line">print(ngram_vect.get_feature_names())</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">5567</span>, <span class="number">31260</span>)</span><br><span class="line">[<span class="string">'008704050406 sp'</span>, <span class="string">'0089mi last'</span>, <span class="string">'0121 2025050'</span>, <span class="string">'01223585236 xx'</span>, <span class="string">'01223585334 cum'</span>, <span class="string">'0125698789 ring'</span>, <span class="string">'02 user'</span>, <span class="string">'020603 2nd'</span>, <span class="string">'0207 153'</span>, <span class="string">'02072069400 bx'</span>, <span class="string">'02073162414 cost'</span>, <span class="string">'02085076972 repli'</span>, <span class="string">'020903 2nd'</span>, <span class="string">'021 3680'</span>, <span class="string">'021 3680offer'</span>, <span class="string">'050703 tcsbcm4235wc1n3xx'</span>, <span class="string">'06 good'</span>, <span class="string">'07046744435 arrang'</span>, <span class="string">'07090298926 reschedul'</span>, <span class="string">'07099833605 reschedul'</span>, <span class="string">'07123456789 87077'</span>, <span class="string">'0721072 find'</span>, <span class="string">'07732584351 rodger'</span>, ...]</span><br></pre></td></tr></table></figure><p>You can see that we still have the same 5,567 rows but now instead of the 8,000 that we saw before, you can seen that there’s over 31,000 columns.  That means 31,000 unique combinations of two words. In these feature names, you’ll see two-word combinations.</p><p>A smaller example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data_sample = data[<span class="number">0</span>:<span class="number">20</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Only search for bigram (2, 2)</span></span><br><span class="line"><span class="comment"># if search both unigram and bigram, do (1, 2)</span></span><br><span class="line">ngram_vect_sample = CountVectorizer(ngram_range = (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">X_counts_sample = ngram_vect_sample.fit_transform(data_sample[<span class="string">"cleaned_text"</span>])</span><br><span class="line">print(X_counts_sample.shape)</span><br><span class="line">print(ngram_vect_sample.get_feature_names())</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">20</span>, <span class="number">198</span>)</span><br><span class="line">[<span class="string">'09061701461 claim'</span>, <span class="string">'100 20000'</span>, <span class="string">'100000 prize'</span>, <span class="string">'11 month'</span>, <span class="string">'12 hour'</span>, <span class="string">'150pday 6day'</span>, <span class="string">'16 tsandc'</span>, <span class="string">'20000 pound'</span>, <span class="string">'2005 text'</span>, <span class="string">'21st may'</span>, <span class="string">'4txtú120 poboxox36504w45wq'</span>, <span class="string">'6day 16'</span>, <span class="string">'81010 tc'</span>, <span class="string">'87077 eg'</span>, <span class="string">'87077 trywal'</span>, <span class="string">'87121 receiv'</span>, <span class="string">'87575 cost'</span>, <span class="string">'900 prize'</span>, <span class="string">'aft finish'</span>, <span class="string">'aid patent'</span>, <span class="string">'alright way'</span>, <span class="string">'anymor tonight'</span>, <span class="string">'appli 08452810075over18'</span>, <span class="string">'appli repli'</span>, <span class="string">'ard smth'</span>, <span class="string">'around though'</span>, <span class="string">'brother like'</span>, <span class="string">'call 09061701461'</span>, <span class="string">'call mobil'</span>, <span class="string">'caller press'</span>, <span class="string">'callertun caller'</span>, <span class="string">'camera free'</span>, <span class="string">'cash 100'</span>, <span class="string">'chanc win'</span>, <span class="string">'claim 81010'</span>, <span class="string">'claim call'</span>, <span class="string">'claim code'</span>, <span class="string">'click httpwap'</span>, <span class="string">'click wap'</span>, <span class="string">'co free'</span>, <span class="string">'code kl341'</span>, <span class="string">'colour mobil'</span>, <span class="string">'comp win'</span>, <span class="string">'copi friend'</span>, <span class="string">'cost 150pday'</span>, <span class="string">'credit click'</span>, <span class="string">'cri enough'</span>, <span class="string">'csh11 send'</span>, <span class="string">'cup final'</span>, <span class="string">'custom select'</span>, <span class="string">'da stock'</span>, <span class="string">'date sunday'</span>, <span class="string">'dont miss'</span>, <span class="string">'dont think'</span>, <span class="string">'dont want'</span>, <span class="string">'eg england'</span>, <span class="string">'eh rememb'</span>, <span class="string">'england 87077'</span>, <span class="string">'england macedonia'</span>, <span class="string">'enough today'</span>, <span class="string">'entitl updat'</span>, <span class="string">'entri questionstd'</span>, <span class="string">'entri wkli'</span>, <span class="string">'even brother'</span>, <span class="string">'fa 87121'</span>, <span class="string">'fa cup'</span>, <span class="string">'feel way'</span>, ...]</span><br></pre></td></tr></table></figure><p>Instead of over 31,000 columns, now we’re back down to 198.  If you remember, that’s still higher than the 192 unigrams that we saw in our last notebook.  At this point, it’s worth noting that using this n-gram range can end up creating a matrix with a ton of features.  If you did an n-gram range of one comma two so that’s grabbing all the unigrams and bigrams.  In the previous session we saw that there are over 8,000 unigrams in the full data set and in this session we saw that there are 31,000 bigrams in the full sample.  Together that’s 39,000 columns that are only using unigrams and bigrams.  Imagine if we added trigrams on top of that.  Just be careful with the n-grams.  It’s definitely worth experimenting to see both what’s going to work within memory and which is going to help you generate the best model.</p><p>Vectorizers output sparse matrices:</p><p><em><strong>Sparse Matrix</strong>: A matrix in which most entries are 0. In the interest of efficient storage, a sparse matrix will be stored by only storing the locations of the non-zero elements.</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_counts_df = pd.DataFrame(X_counts_sample.toarray())</span><br><span class="line">X_counts_df.columns = ngram_vect_sample.get_feature_names()</span><br><span class="line">X_counts_df</span><br></pre></td></tr></table></figure><p>Output:</p><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">vettam set</th><th style="text-align:right">want talk</th><th style="text-align:right">wap link</th><th style="text-align:right">way feel</th><th style="text-align:right">way gota</th><th style="text-align:right">way meet</th><th style="text-align:right">week free</th><th style="text-align:right">win cash</th><th style="text-align:right">win fa</th><th style="text-align:right">winner valu</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td></tr><tr><td style="text-align:right">6</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">7</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">8</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">9</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">10</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">11</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">12</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">13</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">14</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">15</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">16</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">17</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">18</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">19</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td><td style="text-align:right">0</td></tr></tbody></table><p>20 rows × 198 columns</p><p>This is a brief introduction to how you implement n-grams. The value to n-grams over regular count vectorization is that it provides a little bit more context around words. There is certainly a trade-off when you’re choosing your n value for your n-grams. If you select only bigrams, then maybe that’s not enough to provide useful context. If you go all the way up to sevengrams, you’re going to have a ton of features and you’ll only see the same sevengram, in other words, the same sequence of seven words maybe in one text message. In other words what that means is every column of sevengrams would be non zero in only one row and you’d have a massive matrix. N-grams can be powerful but they require a little bit more care in implementing.</p><h2 id="inverse-document-frequency-weighting-tf-idf"><a class="markdownIt-Anchor" href="#inverse-document-frequency-weighting-tf-idf"></a> Inverse Document Frequency Weighting (TF-IDF)</h2><p>TF-IDF creates a document term matrix, where there’s still one row per text message and the columns still represent single unique terms. But instead of the cells representing the count, the cells represent a weighting that’s meant to identify how important a word is to an individual text message.</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mi>t</mi><msub><mi>f</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>×</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mi>N</mi><mrow><mi>d</mi><msub><mi>f</mi><mi>i</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">w_{i,j} = tf_{i,j} \times log\frac{N}{df_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">t</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.2407700000000004em;vertical-align:-0.8804400000000001em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>The above formula lays out how this weighting is determined. It may look a little bit intimidating, but it’s actually quite simple.</p><p>You start with this TF term, which is just the number of times that term I occurs in text message J, divided by the number of terms in text message J. It’s just the percent of terms in this given text message that are this specific word.</p><p>For example:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>=</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">N = 20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><msub><mi>f</mi><mrow><mi>N</mi><mi>L</mi><mi>P</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">df_{NLP} = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mord mathdefault mtight">L</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mi>t</mi><msub><mi>f</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>×</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mi>N</mi><mrow><mi>d</mi><msub><mi>f</mi><mi>i</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">w_{i,j} = tf_{i,j} \times log{\frac{N}{df_i}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">t</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.2407700000000004em;vertical-align:-0.8804400000000001em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>0.</mn><mover accent="true"><mn>33</mn><mo stretchy="true">‾</mo></mover><mo>×</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mn>20</mn><mn>1</mn></mfrac></mrow><annotation encoding="application/x-tex">w_{i,j} = 0.\overline{33} \times log{\frac{20}{1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9277700000000001em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8444400000000001em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">3</span></span></span><span style="top:-3.76444em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>0.</mn><mover accent="true"><mn>33</mn><mo stretchy="true">‾</mo></mover><mo>×</mo><mn>1.301</mn></mrow><annotation encoding="application/x-tex">w_{i,j} = 0.\overline{33} \times 1.301</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9277700000000001em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8444400000000001em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">3</span></span></span><span style="top:-3.76444em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">3</span><span class="mord">0</span><span class="mord">1</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>0.43</mn></mrow><annotation encoding="application/x-tex">w_{i,j} = 0.43</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mord">3</span></span></span></span></span></p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
          <category> Data Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Science </tag>
            
            <tag> Data Processing </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark for Machine Learning and AI</title>
      <link href="/2019/08/20/Spark-for-Machine-Learning-AI/"/>
      <url>/2019/08/20/Spark-for-Machine-Learning-AI/</url>
      
        <content type="html"><![CDATA[<h1 id="introduction-to-the-post"><a class="markdownIt-Anchor" href="#introduction-to-the-post"></a> Introduction to The Post</h1><p>This post is going to describe how to use the Apache Spark Platform for Machine Learning.  It will start by reviewing the basics of the dataframe data structure.  Then, it will cover the pre-processing to both numeric and text data so that is ready to use with Spark’s MLlib machine learning library.  The post will also describe multiple algorithms for clustering, classification and regression.  In the end, it will briefly describe a recommendation system.</p><h1 id="introduction-to-spark"><a class="markdownIt-Anchor" href="#introduction-to-spark"></a> Introduction to Spark</h1><p>Spark is a distributed, data processing platform for big data.  Distributed means Spark runs on a cluster of servers and the data processing means it performs computations such as ETL and modelling.  In the case of Spark, some of the most interesting computations are related to machine learning and data analysis.  Big data is a term broadly applied to data sets that are not easily analyzed on a single server or using older data management systems that were designed to run on a single server.  Spark is becoming increasingly polyglot with support for multiple languages.  Software engineers familiar with Scala and Java can use those languages while data scientists who prefer Python and R can work with those languages.</p><p>This post will use Python as programming language.  Spark uses a modular architecture that allows for multiple components or packages.  These include MLlib for machine learning, Spark SQL for relational querying, Spark Streaming for continuous processing of streaming data, and GraphX for graph analysis, such as social network analysis.  Spark is a generalized computation platform designed to manage large data sets.  It’s found use in a wide number of industries and applications, including real-time monitoring of financial data, text analysis related to competitive intelligence and compliance, analyzing how customers use eCommerce sites, and healthcare applications, such as analyzing genomes.</p><h1 id="steps-in-machine-learning-process"><a class="markdownIt-Anchor" href="#steps-in-machine-learning-process"></a> Steps in Machine Learning Process</h1><p>There are three broad steps in the machine learning process.</p><p>The first is preprocessing, which includes collecting, reformatting, and transforming data, so that it’s readily used by machine learning algorithms.</p><p>The second step is model building, in which machine learning algorithms are applied to training data to build models.  Models are pieces of code that capture the information implicit in training data.</p><p>The last step is validation, in which to measure how well models are performing.  There are multiple ways to measure performance.  The preprocessing phase includes extracting, transforming, and loading data.  This is similar to the ETL process used in business intelligence and data warehousing.</p><h1 id="creating-spark-session-and-basic-dataframe-processing"><a class="markdownIt-Anchor" href="#creating-spark-session-and-basic-dataframe-processing"></a> Creating Spark Session and Basic Dataframe Processing</h1><p>The following code is going to import all packages to use spark commands:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> to_timestamp</span><br></pre></td></tr></table></figure><h2 id="create-spark-session"><a class="markdownIt-Anchor" href="#create-spark-session"></a> Create Spark Session</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create Session</span></span><br><span class="line">spark = SparkSession.builder.master(<span class="string">'yarn'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Configure the Session</span></span><br><span class="line">spark.conf.set(<span class="string">"spark.executor.memory"</span>, <span class="string">"8g"</span>)</span><br><span class="line">spark.conf.set(<span class="string">'spark.executor.cores'</span>, <span class="string">'3'</span>)</span><br><span class="line">spark.conf.set(<span class="string">'spark.cores.max'</span>, <span class="string">'3'</span>)</span><br><span class="line">spark.conf.set(<span class="string">"spark.driver.memory"</span>,<span class="string">'8g'</span>)</span><br></pre></td></tr></table></figure><h2 id="basic-dataframe-processing"><a class="markdownIt-Anchor" href="#basic-dataframe-processing"></a> Basic Dataframe Processing</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the file path</span></span><br><span class="line">address = <span class="string">"hdfs://10.22.17.39:9000"</span></span><br><span class="line">sales_path = <span class="string">f"<span class="subst">&#123;address&#125;</span>/data/sales/"</span></span><br></pre></td></tr></table></figure><p>There are 3 ways to read csv files:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1st way to read csv file</span></span><br><span class="line">df = spark.read.csv(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2nd way to read csv file, similar to 3rd way</span></span><br><span class="line">df2 = spark.read.format(<span class="string">"csv"</span>).option(<span class="string">"header"</span>, <span class="string">"true"</span>).load(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3rd way to read csv file, similar to 2nd way</span></span><br><span class="line"><span class="comment"># Suggested way to read, many options to specify</span></span><br><span class="line">df3 = spark.read.load(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>,</span><br><span class="line">                     format=<span class="string">"csv"</span>, sep=<span class="string">"|"</span>, inferSchema=<span class="string">"true"</span>, header=<span class="string">"true"</span>, timestampFormat=<span class="string">"yyyy.MM.dd HH:mm:ss"</span>)</span><br></pre></td></tr></table></figure><p>Printing Schema:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Basic</span></span><br><span class="line">df</span><br><span class="line"></span><br><span class="line"><span class="comment"># A bit more details</span></span><br><span class="line">df.schema</span><br><span class="line">display(df3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># A more structured details</span></span><br><span class="line">df.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show data types for each columns</span></span><br><span class="line">df.dtypes</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show a summary of some calculated values like MAX, MIN, MEAN, COUNT for each column</span></span><br><span class="line">df.describe().show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Explain the physical plan for the dataframe</span></span><br><span class="line">df.explain()</span><br></pre></td></tr></table></figure><p>Getting Some Contents:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print column names</span></span><br><span class="line">df.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Showing the dataframe</span></span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Showing the first row in dataframe</span></span><br><span class="line">df.first()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get first 5 rows</span></span><br><span class="line">df.take(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Counting the number of rows</span></span><br><span class="line">df.count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Take only 10% of the data</span></span><br><span class="line">sample_df = df.sample(<span class="literal">False</span>, <span class="number">0.1</span>)</span><br><span class="line">sample_df.count()</span><br></pre></td></tr></table></figure><p>Basic Queries:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Filtering Contents</span></span><br><span class="line">emp_mgrs_df = df.filter(<span class="string">"salary &gt;= 100000"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Seleting Columns to Show</span></span><br><span class="line">emp_mgrs_df.select(<span class="string">"salary"</span>).show()</span><br></pre></td></tr></table></figure><p>A bit more advanced query examples:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select unique values within a column and sort it in ascending order</span></span><br><span class="line">df.select(<span class="string">"PRODUCT_KEY"</span>).distinct().orderBy(<span class="string">"PRODUCT_KEY"</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter the type and select some useful columns</span></span><br><span class="line">df.filter(df3[<span class="string">'TRANSACTION_TYPE_NAME'</span>] == <span class="string">'Item'</span>).select(<span class="string">'PRODUCT_KEY'</span>, <span class="string">'TRANSACTION_ID'</span>, <span class="string">'ORDER_NUM'</span>, <span class="string">'ITEM_QUANTITY_VAL'</span>, <span class="string">'ITEM_AMT'</span>, <span class="string">'ITEM_UNIT_PRICE_AMT'</span>, <span class="string">'TRANSACTION_DT'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select userful columns and group them by the keys, then calculate the sum of quantity for each key and sort it in a decending order.</span></span><br><span class="line">df.select(<span class="string">"PRODUCT_KEY"</span>, <span class="string">"ITEM_QUANTITY_VAL"</span>).groupBy(<span class="string">"PRODUCT_KEY"</span>).sum(<span class="string">"ITEM_QUANTITY_VAL"</span>).sort(<span class="string">"sum(ITEM_QUANTITY_VAL)"</span>, ascending = <span class="literal">False</span>).show()</span><br></pre></td></tr></table></figure><p>Some Useful Functions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This allow the programme to retrive the results from terminal</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_path</span><span class="params">(path)</span>:</span></span><br><span class="line">    arguments = <span class="string">"hdfs dfs -ls "</span>+ path +<span class="string">" | awk '&#123;print $8&#125;'"</span></span><br><span class="line">    proc = subprocess.Popen(arguments, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    s_output, s_err = proc.communicate()</span><br><span class="line">    all_files_path = s_output.decode(<span class="string">'utf-8'</span>).split()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> all_files_path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform date values and make some new columns to display</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_date_n_sales</span><span class="params">(dataframe)</span>:</span></span><br><span class="line">    filtered_sales = filter_sales(dataframe)</span><br><span class="line">    expand_date_n_sales = filtered_sales.select(<span class="string">"PRODUCT_KEY"</span>, <span class="string">"ITEM_QUANTITY_VAL"</span>, <span class="string">"TRANSACTION_DT"</span>,</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'Y'</span>).alias(<span class="string">'year'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'M'</span>).alias(<span class="string">'month'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'D'</span>).alias(<span class="string">'day'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'W'</span>).alias(<span class="string">'week_no'</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> expand_date_n_sales</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loop through all files to get the data and merge together</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_cleaned_sales</span><span class="params">(address, path)</span>:</span></span><br><span class="line">    all_files_path = get_path(path)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(all_files_path)):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            first_raw_df = load_data(address, all_files_path[i])</span><br><span class="line">            df = expand_date_n_sales(first_raw_df)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            raw_df = load_data(address, all_files_path[i])</span><br><span class="line">            tmp_df = expand_date_n_sales(raw_df)</span><br><span class="line">            df = df.union(tmp_df)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure><h1 id="components-of-spark-mllib"><a class="markdownIt-Anchor" href="#components-of-spark-mllib"></a> Components of Spark MLlib</h1><p>The MLlib package has three types of functions.</p><p>The first is machine learning algorithms.  The set of algorithms currently includes algorithms for classifications, which is for categorizing something, such as a customer likely to leave for a competitor.  Regression, which is used for predicting a numeric value like a home price.  Clustering is used to group similar items together.  Unlike classification, there are no predefined groups, so this is really useful when exploring data.  Finally, there’s topic modeling, which is a way to identify themes in a text.</p><p>The second group is workflows.  Workflow components help organize commonly used steps, like pre-processing operations and tuning.  This makes it easy to run a sequence of steps repeatedly while varying some parameters of the process.</p><p>Utilities are lower level functions that give you access to distributed linear algebra and statistics functions.</p><h1 id="introduction-to-preprocessing"><a class="markdownIt-Anchor" href="#introduction-to-preprocessing"></a> Introduction to Preprocessing</h1><p>There are two types of pre-processing, numeric and text pre-processing.</p><h2 id="numeric"><a class="markdownIt-Anchor" href="#numeric"></a> Numeric</h2><h3 id="normalisation-minmaxscaler"><a class="markdownIt-Anchor" href="#normalisation-minmaxscaler"></a> Normalisation (MinMaxScaler)</h3><p>Normalising maps data values from their original range to the range of zero to one.  It’s used to avoid problems when some attributes have large ranges and others have small ranges.  For example, salaries have a large range, but years of employment has a small range.</p><h3 id="standardisation-standardscaler"><a class="markdownIt-Anchor" href="#standardisation-standardscaler"></a> Standardisation (StandardScaler)</h3><p>Standardising maps data values from their original range to a range of negative one to one and it also has a mean value of zero.  This transformation creates a normal distribution with a standard deviation of one.  This transforms our data into a bell curve shape formation.  It’s used when attributes have different scales, and the machine learning algorithm you’re using assumes a normal distribution.</p><h3 id="partition-bucketiser"><a class="markdownIt-Anchor" href="#partition-bucketiser"></a> Partition (Bucketiser)</h3><p>Partitioning maps data values from continuous values to buckets, like histograms.  Deciles and percentiles are examples of buckets.  It’s useful when you want to work with groups of values instead of a continuous range of values.</p><h2 id="text"><a class="markdownIt-Anchor" href="#text"></a> Text</h2><h3 id="tokenisation-tokeniser"><a class="markdownIt-Anchor" href="#tokenisation-tokeniser"></a> Tokenisation (Tokeniser)</h3><p>This transformation maps text from a single string to a set of tokens, or words. For example, the sentence, quote, “This is a Sentence,” can be mapped into a list of tokens, or words, such as the four word list shown below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">"This"</span>, <span class="string">"is"</span>, <span class="string">"a"</span>, <span class="string">"sentence"</span>]</span><br></pre></td></tr></table></figure><h3 id="term-frequency-inverse-document-frequency-tf-idf-hashing-tf"><a class="markdownIt-Anchor" href="#term-frequency-inverse-document-frequency-tf-idf-hashing-tf"></a> Term Frequency Inverse Document Frequency (TF-IDF) - (Hashing TF)</h3><p>This method maps text from a single, typically long string, to a vector, indicating the frequency of each word in a text relative to a group of texts such as a corpus. This transformation is widely used in text classification.  TF-IDF captures the intuition that infrequently used words are more useful for distinguishing categories of text than frequently used words.</p><h1 id="introduction-to-clustering"><a class="markdownIt-Anchor" href="#introduction-to-clustering"></a> Introduction to Clustering</h1><p>Often when working with new data sets, it helps to explore the data and look for macro-level structures such as broad clusters of data.  Clustering algorithms group data into clusters that allow us to see how large data sets can break down into distinct subgroups.  K-means is widely used and works well for finding clusters in small and mid-sized data sets.  For large data sets, the Bisecting K-means algorithms can be faster.</p><h2 id="k-means-clustering"><a class="markdownIt-Anchor" href="#k-means-clustering"></a> K-means Clustering</h2><p><strong><em>Don’t forget to create a spark session before using spark!</em></strong></p><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br></pre></td></tr></table></figure><p>Create a dataframe:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cluster_df = spark.read.csv(<span class="string">"./ex/Ch03/03_02/clustering_dataset.csv"</span>, header = <span class="literal">True</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Select all 75 rows of data</span></span><br><span class="line">cluster_df.show(<span class="number">75</span>)</span><br></pre></td></tr></table></figure><p>Transform data to a feature vector:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(imputCols = [<span class="string">"col1"</span>, <span class="string">"col2"</span>, <span class="string">"col3"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">vcluster_df = vectorAssembler.transform(cluster_df)</span><br></pre></td></tr></table></figure><p>Setup K-means algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the cluster number</span></span><br><span class="line">kmeans = KMeans().setK(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set where the k-means algorithm starts</span></span><br><span class="line">kmeans = kmeans.setSeed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the data</span></span><br><span class="line">kmodel = kmeans.fit(vcluster_df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the centers of the clusters</span></span><br><span class="line">centers = kmodel.clusterCenters()</span><br><span class="line"></span><br><span class="line">centers</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">35.88461538</span>, <span class="number">31.46153846</span>, <span class="number">34.42307692</span>]),</span><br><span class="line"> array([<span class="number">5.12</span>, <span class="number">5.84</span>, <span class="number">4.84</span>]),</span><br><span class="line"> array([<span class="number">80.</span>        , <span class="number">79.20833333</span>, <span class="number">78.29166667</span>])]</span><br></pre></td></tr></table></figure><h2 id="hierarchical-clustering"><a class="markdownIt-Anchor" href="#hierarchical-clustering"></a> Hierarchical Clustering</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> BisectingKMeans</span><br></pre></td></tr></table></figure><p>Setup Bisecting KMeans algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bkmeans = BisectingKMeans().setK(<span class="number">3</span>)</span><br><span class="line">bkmeans = bkmeans.setSeed(<span class="number">1</span>)</span><br><span class="line">bkmodel = bkmeans.fit(vcluster_df)</span><br><span class="line">bkcenters = bkmodel.clusterCenters()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">5.12</span>, <span class="number">5.84</span>, <span class="number">4.84</span>]),</span><br><span class="line"> array([<span class="number">35.88461538</span>, <span class="number">31.46153846</span>, <span class="number">34.42307692</span>]),</span><br><span class="line"> array([<span class="number">80.</span>        , <span class="number">79.20833333</span>, <span class="number">78.29166667</span>])]</span><br></pre></td></tr></table></figure><h1 id="introduction-to-classification"><a class="markdownIt-Anchor" href="#introduction-to-classification"></a> Introduction to Classification</h1><p>Classification algorithms are useful when we have datasets that we want to be able to split into different categories.  So, for example, we might have a number of pieces of data that fall into Category A or Category B, and sometimes it’s not so obvious where certain things should fall.  Classification algorithms help us identify boundaries between different categories and make it easy for us to then decide how to assign a new entity to a particular category.</p><h2 id="preprocessing-the-iris-dataset"><a class="markdownIt-Anchor" href="#preprocessing-the-iris-dataset"></a> Preprocessing The Iris Dataset</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br></pre></td></tr></table></figure><p>Create A Spark Session:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder.master(<span class="string">'local'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br></pre></td></tr></table></figure><p>Create Spark Dataframe:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iris_df = spark.read.csv(<span class="string">"iris.data"</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line">iris_df.show()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+---+---+---+---+-----------+</span><br><span class="line">|_c0|_c1|_c2|_c3|        _c4|</span><br><span class="line">+---+---+---+---+-----------+</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.5</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.9</span>|<span class="number">3.0</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.7</span>|<span class="number">3.2</span>|<span class="number">1.3</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.6</span>|<span class="number">3.1</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.0</span>|<span class="number">3.6</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.9</span>|<span class="number">1.7</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.6</span>|<span class="number">3.4</span>|<span class="number">1.4</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.0</span>|<span class="number">3.4</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.4</span>|<span class="number">2.9</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.9</span>|<span class="number">3.1</span>|<span class="number">1.5</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.7</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.8</span>|<span class="number">3.4</span>|<span class="number">1.6</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.8</span>|<span class="number">3.0</span>|<span class="number">1.4</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.3</span>|<span class="number">3.0</span>|<span class="number">1.1</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.8</span>|<span class="number">4.0</span>|<span class="number">1.2</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.7</span>|<span class="number">4.4</span>|<span class="number">1.5</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.9</span>|<span class="number">1.3</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.5</span>|<span class="number">1.4</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.7</span>|<span class="number">3.8</span>|<span class="number">1.7</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.8</span>|<span class="number">1.5</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">+---+---+---+---+-----------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure><p>Rename all columns:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">iris_df = iris_df.select(col(<span class="string">"_c0"</span>).alias(<span class="string">"sepal_length"</span>),</span><br><span class="line">                         col(<span class="string">"_c1"</span>).alias(<span class="string">"sepal_width"</span>),</span><br><span class="line">                         col(<span class="string">"_c2"</span>).alias(<span class="string">"petal_length"</span>),</span><br><span class="line">                         col(<span class="string">"_c3"</span>).alias(<span class="string">"petal_width"</span>),</span><br><span class="line">                         col(<span class="string">"_c4"</span>).alias(<span class="string">"species"</span>)</span><br><span class="line">                        )</span><br><span class="line"></span><br><span class="line">iris_df.show()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+</span><br></pre></td></tr></table></figure><p>Transform the dataframe into vector structure:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(inputCols = [<span class="string">"sepal_length"</span>, <span class="string">"sepal_width"</span>, <span class="string">"petal_length"</span>, <span class="string">"petal_width"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">viris_df = vectorAssembler.transform(iris_df)</span><br><span class="line"></span><br><span class="line">viris_df.show()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|         features|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.7</span>,<span class="number">3.2</span>,<span class="number">1.3</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.6</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.7</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.4</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.4</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.4</span>,<span class="number">2.9</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.7</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.4</span>,<span class="number">1.6</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.3</span>,<span class="number">3.0</span>,<span class="number">1.1</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.8</span>,<span class="number">4.0</span>,<span class="number">1.2</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">4.4</span>,<span class="number">1.5</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.3</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">3.8</span>,<span class="number">1.7</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.8</span>,<span class="number">1.5</span>,<span class="number">0.3</span>]|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br></pre></td></tr></table></figure><p>Convert string value of species into numeric values:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">indexer = StringIndexer(inputCol = <span class="string">"species"</span>, outputCol = <span class="string">"label"</span>)</span><br><span class="line">iviris_df = indexer.fit(viris_df).transform(viris_df)</span><br><span class="line"></span><br><span class="line">iviris_df.show()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|         features|label|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.7</span>,<span class="number">3.2</span>,<span class="number">1.3</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.6</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.7</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.4</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.4</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.4</span>,<span class="number">2.9</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.7</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.4</span>,<span class="number">1.6</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.3</span>,<span class="number">3.0</span>,<span class="number">1.1</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.8</span>,<span class="number">4.0</span>,<span class="number">1.2</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">4.4</span>,<span class="number">1.5</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.3</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">3.8</span>,<span class="number">1.7</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.8</span>,<span class="number">1.5</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br></pre></td></tr></table></figure><h2 id="naive-bayes-classification"><a class="markdownIt-Anchor" href="#naive-bayes-classification"></a> Naive Bayes Classification</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> NaiveBayes</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br></pre></td></tr></table></figure><p>Split the dataset into train and test datasets:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">splits = iviris_df.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>], <span class="number">1</span>)</span><br><span class="line">train_df = splits[<span class="number">0</span>]</span><br><span class="line">test_df = splits[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>Train the model using Naive Bayes Classifier and make the prediction:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nb = NaiveBayes(modelType = <span class="string">"multinomial"</span>)</span><br><span class="line">nbmodel = nb.fit(train_df)</span><br><span class="line"></span><br><span class="line">predictions_df = nbmodel.transform(test_df)</span><br><span class="line">predictions_df.take(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Row(sepal_length=<span class="number">4.5</span>, sepal_width=<span class="number">2.3</span>, petal_length=<span class="number">1.3</span>, petal_width=<span class="number">0.3</span>, species=<span class="string">'Iris-setosa'</span>, features=DenseVector([<span class="number">4.5</span>, <span class="number">2.3</span>, <span class="number">1.3</span>, <span class="number">0.3</span>]), label=<span class="number">0.0</span>, rawPrediction=DenseVector([<span class="number">-10.3605</span>, <span class="number">-11.0141</span>, <span class="number">-11.7112</span>]), probability=DenseVector([<span class="number">0.562</span>, <span class="number">0.2924</span>, <span class="number">0.1456</span>]), prediction=<span class="number">0.0</span>)]</span><br></pre></td></tr></table></figure><p>Evaluate the accuracy:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">evaluator = MulticlassClassificationEvaluator(labelCol = <span class="string">"label"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">nbaccuarcy = evaluator.evaluate(predictions_df)</span><br><span class="line"></span><br><span class="line">nbaccuarcy</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.5862068965517241</span></span><br></pre></td></tr></table></figure><h2 id="multilayer-perceptron-classification"><a class="markdownIt-Anchor" href="#multilayer-perceptron-classification"></a> Multilayer Perceptron Classification</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> MultilayerPerceptronClassifier</span><br></pre></td></tr></table></figure><p>Set the layers and do some training using Multilayer Perceptron Classifier as well as making predictions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Have 4 layers multilayer perceptron,</span></span><br><span class="line"><span class="comment"># the input is 4 neurons, two hidden layers are 5 neurons each and output layer has 3 neurons</span></span><br><span class="line">layers = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">mlp = MultilayerPerceptronClassifier(layers = layers, seed = <span class="number">1</span>)</span><br><span class="line">mlp_model = mlp.fit(train_df)</span><br><span class="line">mlp_predictions = mlp_model.transform(test_df)</span><br></pre></td></tr></table></figure><p>Evaluate the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mlp_evaluator = MulticlassClassificationEvaluator(metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">mlp_accuracy = mlp_evaluator.evaluate(mlp_predictions)</span><br><span class="line"></span><br><span class="line">mlp_accuracy</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.9482758620689655</span></span><br></pre></td></tr></table></figure><h2 id="decision-trees-classification"><a class="markdownIt-Anchor" href="#decision-trees-classification"></a> Decision Trees Classification</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> DecisionTreeClassifier</span><br></pre></td></tr></table></figure><p>Train the model using Decision Trees Claccifier as well as making predictions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(labelCol = <span class="string">"label"</span>, featuresCol = <span class="string">"features"</span>)</span><br><span class="line">dt_model = dt.fit(train_df)</span><br><span class="line"></span><br><span class="line">dt_predictions = dt_model.transform(test_df)</span><br></pre></td></tr></table></figure><p>Evaluate the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt_evaluator = MulticlassClassificationEvaluator(labelCol = <span class="string">"label"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">dt_accuracy = dt_evaluator.evaluate(dt_predictions)</span><br><span class="line"></span><br><span class="line">dt_accuracy</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.9310344827586207</span></span><br></pre></td></tr></table></figure><h1 id="introduction-to-regresssion"><a class="markdownIt-Anchor" href="#introduction-to-regresssion"></a> Introduction to Regresssion</h1><p>Regression techniques allow us to make predictions about numeric values.  For example, if we have a product and the price of that product has been steadily rising over time, we might want to be able to estimate what the price will be in the future.  Now we could look at prices over a period of time and try and fit a line to those price points over time.  That line is useful because it goes out into the future and we can use it to make projections about what the price might be at some future point.</p><h2 id="pre-processing-the-dataset"><a class="markdownIt-Anchor" href="#pre-processing-the-dataset"></a> Pre-processing The Dataset</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br></pre></td></tr></table></figure><p>Create a spark session:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder.master(<span class="string">'local'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br></pre></td></tr></table></figure><p>Read the CSV file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pp_df = spark.read.csv(<span class="string">"power_plant.csv"</span>)</span><br><span class="line">pp_df</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]</span><br></pre></td></tr></table></figure><p>Read the CSV file again correctly:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pp_df = spark.read.csv(<span class="string">"power_plant.csv"</span>, header = <span class="literal">True</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line">pp_df</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[AT: double, V: double, AP: double, RH: double, PE: double]</span><br></pre></td></tr></table></figure><p>Creating a feature vector:</p><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(inputCols = [<span class="string">"AT"</span>, <span class="string">"V"</span>, <span class="string">"AP"</span>, <span class="string">"RH"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">vpp_df = vectorAssembler.transform(pp_df)</span><br><span class="line"></span><br><span class="line">vpp_df.take(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Row(AT=<span class="number">14.96</span>, V=<span class="number">41.76</span>, AP=<span class="number">1024.07</span>, RH=<span class="number">73.17</span>, PE=<span class="number">463.26</span>, features=DenseVector([<span class="number">14.96</span>, <span class="number">41.76</span>, <span class="number">1024.07</span>, <span class="number">73.17</span>]))]</span><br></pre></td></tr></table></figure><h2 id="linear-regression"><a class="markdownIt-Anchor" href="#linear-regression"></a> Linear Regression</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> LinearRegression</span><br></pre></td></tr></table></figure><p>Train the model using Linear Regression:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">lr_model = lr.fit(vpp_df)</span><br></pre></td></tr></table></figure><p>Coefficients:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.coefficients</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DenseVector([<span class="number">-1.9775</span>, <span class="number">-0.2339</span>, <span class="number">0.0621</span>, <span class="number">-0.1581</span>])</span><br></pre></td></tr></table></figure><p>Intercept:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.intercept</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">454.6092744523414</span></span><br></pre></td></tr></table></figure><p>Root Mean Squared Error:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.summary.rootMeanSquaredError</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4.557126016749488</span></span><br></pre></td></tr></table></figure><p>Save the model:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.save(<span class="string">"lr1.model"</span>)</span><br></pre></td></tr></table></figure><h2 id="decision-tree-regression"><a class="markdownIt-Anchor" href="#decision-tree-regression"></a> Decision Tree Regression</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br></pre></td></tr></table></figure><p>Split the dataset into train and test dataset:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">splits = vpp_df.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line">train_df = splits[<span class="number">0</span>]</span><br><span class="line">test_df = splits[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>Train the model and make the predictions using Decision Tree Regression:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeRegressor(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">dt_model = dt.fit(train_df)</span><br><span class="line"></span><br><span class="line">dt_predictions = dt_model.transform(test_df)</span><br></pre></td></tr></table></figure><p>Evaluate the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt_evaluator = RegressionEvaluator(labelCol = <span class="string">"PE"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"rmse"</span>)</span><br><span class="line">rmse = dt_evaluator.evaluate(dt_predictions)</span><br><span class="line"></span><br><span class="line">rmse</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4.459494278528065</span></span><br></pre></td></tr></table></figure><h2 id="gradient-boosted-tree-regression"><a class="markdownIt-Anchor" href="#gradient-boosted-tree-regression"></a> Gradient-boosted Tree Regression</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> GBTRegressor</span><br></pre></td></tr></table></figure><p>Train the model and make the predictions using Gradient-boosted Tree Regression:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gbt = GBTRegressor(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">gbt_model = gbt.fit(train_df)</span><br><span class="line"></span><br><span class="line">gbt_predictions = gbt_model.transform(test_df)</span><br></pre></td></tr></table></figure><p>Evaluate the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gbt_evaluator = RegressionEvaluator(labelCol = <span class="string">"PE"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"rmse"</span>)</span><br><span class="line">gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)</span><br><span class="line"></span><br><span class="line">gbt_rmse</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3.976988494544201</span></span><br></pre></td></tr></table></figure><h1 id="understand-recommendation-systems"><a class="markdownIt-Anchor" href="#understand-recommendation-systems"></a> Understand Recommendation Systems</h1><p>A common problem in machine learning is making recommendations.  There’s two general ways of doing this.  One is called Collaborative Filtering. Let’s imagine you run an online bookstore, and you have a number of customers.  And these customers all like reading both the brown book and the red book.  Now a new customer comes along and indicates that they really enjoyed reading the red book.  What other books can we recommend to them? Definitely the brown book, since other people who have read the red book also enjoy reading the brown book.  This is an example of collaborative filtering.  Another way to make recommendations is based on the properties of the items that you’re working with. For example, if we have a customer who really enjoys readying Sci-fi, we might want to recommend other science fiction books to them, but not necessarily biographies.  Spark MLlib supports Collaborative Filtering, and it works by filling in something known as the user-item matrix.  So we can think of users as customers and items as books.  In this example below, we have a customer who likes item one and two and item four.  User number two, or customer number two, also likes item two and also likes item three.  Now, we’ll notice that user four has something in common with both user one and user three.  That means we probably want to recommend item two to user four.  This is an example of collaborative filtering.  This is the type of recommendation system that Spark MLlib supports.</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Item1</th><th style="text-align:center">Item2</th><th style="text-align:center">Item3</th><th style="text-align:center">Item4</th></tr></thead><tbody><tr><td style="text-align:center">User1</td><td style="text-align:center">x</td><td style="text-align:center">x</td><td style="text-align:center"></td><td style="text-align:center">x</td></tr><tr><td style="text-align:center">User1</td><td style="text-align:center"></td><td style="text-align:center">x</td><td style="text-align:center">x</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">User1</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">x</td></tr><tr><td style="text-align:center">User1</td><td style="text-align:center">x</td><td style="text-align:center">?</td><td style="text-align:center">x</td><td style="text-align:center"></td></tr></tbody></table><h2 id="collaborative-filtering"><a class="markdownIt-Anchor" href="#collaborative-filtering"></a> Collaborative Filtering</h2><p>Collaborative filtering follows the same patterns we’ve used repeatedly in this post.</p><p>First we start with preprocessing.  We’re going to use the alternating least squares method that’s provided by Spark MLlib, and, to use that, we just import the ALS code from pyspark.ml.recommendation package.  And then we build a DataFrame using user-item ratings.</p><p>When it comes to modeling, we create an ALS object and, when we do that, we have to specify the user, the item, and the rating columns in our data frames.  And then we train the model using fit and fit is part of the ALS project.  And then when it’s time to evaluate, we create predictions using the transform of the ALS model and we apply that to our test data.  We create a RegressionEvaluator object and we use the evaluate function of that RegressionEvaluator object to calculate the root mean squared error, and that’ll give us a measure of how well our collaborative filtering is making recommendations.</p><h1 id="tips-for-using-spark-mllib"><a class="markdownIt-Anchor" href="#tips-for-using-spark-mllib"></a> Tips for Using Spark MLlib</h1><p>Let’s review some tips for working with Spark MLlib.</p><p>There are three basic stages of building machine learning models.  There’s a pre-processing phase where we collect, reformat, and transform the data.  And once we have that data, we can build our models using a variety of machine learning algorithms.  And then we want to make sure we evaluate our data to assess the quality of the models we built.</p><p>With that framework in mind, let’s look at some tips to make each of these stages go smoothly. First, when we’re pre-processing, we want to first load our data into DataFrames.  If you’re working with text files, it helps to have headers or column names in the text file.  When you read a file, make sure you use the inferSchema = True option.  That’ll make sure that things like dates and numeric values get mapped to their appropriate data type.  Use the VectorAssembler to create feature vectors and the StringIndexer to map from strings to numeric indexes.</p><p>During the model building phase, make sure to split your data into training and test sets. We use the training data to fit our models and then the test data to apply transformations to create predictions.  When we’re done building the model, we want to validate them.  Using the MLlib evaluators is recommanded.  The two that we looked at were the MulticlassClassificationEvaluator and the RegressionEvaluator.  Just be sure to use the right one for the kind of algorithm you’re working with.  Also, be sure to experiment with multiple algorithms.  Once you’ve gone through the pre-processing phase, it’s very easy to test other algorithms so take advantage of that.  Also, vary hyperparameters for the algorithms you’re working with.  Sometimes you can get slightly better performance just by changing a hyperparameter.</p><p>Where do we go from here? Well first I’d recommend consulting the MLlib documentation.  It’s really high quality documentation and it provides details on the APIs and includes extensive examples.  When you’re ready to work with other data sets, look at the Kaggle website that has both machine learning data sets and articles about machine learning.  Now Spark is designed for working with big data so if you’re ready to work with machine learning at big data scales, consult the AWS data sets.  These are public data sets that are freely available from the AWS cloud service.  Spark and MLlib are both under active development. So as you go forward working with MLlib, be sure to check back at the Spark MLlib website for updates and new features.</p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
          <category> Big Data </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Big Data </tag>
            
            <tag> Data Science </tag>
            
            <tag> Data Processing </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> AI </tag>
            
            <tag> Model </tag>
            
            <tag> Query </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop Environment Setup</title>
      <link href="/2019/08/19/Hadoop-Environment-Setup/"/>
      <url>/2019/08/19/Hadoop-Environment-Setup/</url>
      
        <content type="html"><![CDATA[<h1 id="ubuntu-installation"><a class="markdownIt-Anchor" href="#ubuntu-installation"></a> Ubuntu Installation</h1><h2 id="version-ubuntu-desktop-18042-lts"><a class="markdownIt-Anchor" href="#version-ubuntu-desktop-18042-lts"></a> Version: <a href="https://ubuntu.com/download/desktop" target="_blank" rel="noopener">Ubuntu Desktop 18.04.2 LTS</a></h2><h2 id="installation-tutorial-install-ubuntu-desktop"><a class="markdownIt-Anchor" href="#installation-tutorial-install-ubuntu-desktop"></a> Installation Tutorial: <a href="https://tutorials.ubuntu.com/tutorial/tutorial-install-ubuntu-desktop#0" target="_blank" rel="noopener">Install Ubuntu Desktop</a></h2><h2 id="disable-auto-update"><a class="markdownIt-Anchor" href="#disable-auto-update"></a> Disable Auto Update</h2><h2 id="disable-auto-shut-down-and-sleep"><a class="markdownIt-Anchor" href="#disable-auto-shut-down-and-sleep"></a> Disable Auto Shut Down and Sleep</h2><p><strong><em>Notice: In log in details session, please set your computer’s name as master/slave1/slave2/slave3 and set username as hadoop across all machines.</em></strong></p><h1 id="hadoop-environment-setup"><a class="markdownIt-Anchor" href="#hadoop-environment-setup"></a> Hadoop Environment Setup</h1><h2 id="pre-installation-setup"><a class="markdownIt-Anchor" href="#pre-installation-setup"></a> Pre-installation Setup</h2><h3 id="checking-hostname"><a class="markdownIt-Anchor" href="#checking-hostname"></a> Checking Hostname</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ hostname</span><br><span class="line">slave1</span><br></pre></td></tr></table></figure><h3 id="checking-current-ip-address"><a class="markdownIt-Anchor" href="#checking-current-ip-address"></a> Checking Current IP Address</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ hostname -I</span><br><span class="line">10.22.16.84 172.17.0.1</span><br></pre></td></tr></table></figure><h3 id="install-vim"><a class="markdownIt-Anchor" href="#install-vim"></a> Install vim</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /</span><br><span class="line">hadoop@slave1:/$ <span class="built_in">cd</span> etc</span><br><span class="line">hadoop@slave1:/etc$ sudo apt install vim</span><br></pre></td></tr></table></figure><h3 id="add-ip-addresses"><a class="markdownIt-Anchor" href="#add-ip-addresses"></a> Add IP Addresses</h3><p>Insert the information from the table below into /etc/hosts file.</p><table><thead><tr><th style="text-align:center">IP Addresses</th><th style="text-align:center">Hostnames</th></tr></thead><tbody><tr><td style="text-align:center">10.22.17.39</td><td style="text-align:center">master</td></tr><tr><td style="text-align:center">10.22.16.84</td><td style="text-align:center">slave1</td></tr><tr><td style="text-align:center">10.22.17.150</td><td style="text-align:center">slave2</td></tr><tr><td style="text-align:center">10.22.17.79</td><td style="text-align:center">slave3</td></tr></tbody></table><p>Command to open and insert information:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/etc$ sudo vim hosts</span><br></pre></td></tr></table></figure><p>Check if connections to other machines can be established:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/etc$ ping master</span><br></pre></td></tr></table></figure><h2 id="java-jdk-installation"><a class="markdownIt-Anchor" href="#java-jdk-installation"></a> Java JDK Installation</h2><h3 id="version-java-se-development-kit-8u221-requires-registration"><a class="markdownIt-Anchor" href="#version-java-se-development-kit-8u221-requires-registration"></a> Version: <a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">Java SE Development Kit 8u221</a> (Requires Registration)</h3><h3 id="extract-the-files-to-usrlibjvm"><a class="markdownIt-Anchor" href="#extract-the-files-to-usrlibjvm"></a> Extract the Files to /usr/lib/jvm/</h3><h3 id="add-javas-path-into-path"><a class="markdownIt-Anchor" href="#add-javas-path-into-path"></a> Add Java’s Path into $PATH</h3><p>Open /etc/profile file to write the Java path into:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /etc</span><br><span class="line">hadoop@slave1:~$ sudo vim profile</span><br></pre></td></tr></table></figure><p>Insert the following code into the file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_211</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$CLASSPATH</span>:<span class="variable">$JAVA_HOME</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure><p>Source the file to apply the changes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">source</span> profile</span><br></pre></td></tr></table></figure><p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p><h3 id="check-java-version-and-path"><a class="markdownIt-Anchor" href="#check-java-version-and-path"></a> Check Java Version and Path</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ java -version</span><br><span class="line">java version <span class="string">"1.8.0_211"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_211-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)</span><br><span class="line">hadoop@slave1:~$ <span class="built_in">which</span> java</span><br><span class="line">/usr/lib/jvm/jdk1.8.0_211/bin/java</span><br></pre></td></tr></table></figure><h2 id="setup-ssh"><a class="markdownIt-Anchor" href="#setup-ssh"></a> Setup SSH</h2><p>Setting up this to allow the machines to connect each other without entering passwords.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Installing SSH</span></span><br><span class="line">hadoop@slave1:~$ sudo apt-get install openssh-server</span><br><span class="line"></span><br><span class="line"><span class="comment">#Generate a SSH key</span></span><br><span class="line">hadoop@slave1:~$ ssh-keygen -t rsa</span><br><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> .ssh/</span><br><span class="line"></span><br><span class="line"><span class="comment">#Copy key into authorized_keys file</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment">#To set the file that the owner can read and write on it</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ chmod 0600 authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment">#Configer settings on sshd_config file</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ sudo vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p>Type these lines in the end of the sshd_config file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RSAAuthentication yes</span><br><span class="line">PubkeyAuthentication yes</span><br><span class="line">AuthorizedKeysFile      %h/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p>Restarting the SSH service and copy its ssh id to other machines:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~/.ssh/$ service ssh restart</span><br><span class="line">hadoop@slave1:~/.ssh/$ ssh-copy-id master@master</span><br><span class="line">hadoop@slave1:~/.ssh/$ ssh <span class="string">'master@master'</span></span><br></pre></td></tr></table></figure><h2 id="hadoop-installation"><a class="markdownIt-Anchor" href="#hadoop-installation"></a> Hadoop Installation</h2><h3 id="install-hadoop"><a class="markdownIt-Anchor" href="#install-hadoop"></a> Install Hadoop</h3><ul><li>Version: <a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz" target="_blank" rel="noopener">Hadoop 3.1.2 (Binary)</a></li><li>Move Hadoop folder to /usr/ folder</li><li>Change folder name into hadoop</li><li>Make tmp folder inside of the hadoop folder</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/$ sudo mv hadoop-3.1.2/ /usr/</span><br><span class="line">hadoop@slave1:/$ <span class="built_in">cd</span> usr/</span><br><span class="line">hadoop@slave1:/usr$ sudo mv hadoop-3.1.2/ hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#This line is going to give the permission to the user</span></span><br><span class="line">hadoop@slave1:/usr$ chown -R hadoop:slave1 hadoop/</span><br><span class="line">hadoop@slave1:/usr$ <span class="built_in">cd</span> hadoop/</span><br><span class="line">hadoop@slave1:/usr/hadoop$ mkdir tmp</span><br></pre></td></tr></table></figure><h3 id="add-hadoops-path-into-path"><a class="markdownIt-Anchor" href="#add-hadoops-path-into-path"></a> Add Hadoop’s Path into $PATH</h3><p>Open /etc/profile file to write the Hadoop path into:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /etc</span><br><span class="line">hadoop@slave1:~$ sudo vim profile</span><br></pre></td></tr></table></figure><p>Insert the following code into the file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure><p>Source the file to apply the changes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">source</span> profile</span><br></pre></td></tr></table></figure><p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p><h3 id="configure-hadoop"><a class="markdownIt-Anchor" href="#configure-hadoop"></a> Configure Hadoop</h3><p>Change configeration settings in 5 following files:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Finding the paths on each file</span></span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name hadoop-env.sh</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name core-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name hdfs-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name mapred-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name yarn-site.xml</span><br></pre></td></tr></table></figure><p>5 paths:</p><ul><li><a href="http://hadoop-env.sh" target="_blank" rel="noopener">hadoop-env.sh</a> - hadoop/etc/hadoop/hadoop-env.sh</li><li>core-site.xml - hadoop/etc/hadoop/core-site.xml</li><li>hdfs-site.xml - hadoop/etc/hadoop/hdfs-site.xml</li><li>mapred-site.xml - hadoop/etc/hadoop/mapred-site.xml</li><li>yarn-site.xml - hadoop/etc/hadoop/yarn-site.xml</li></ul><p>Configure <strong>hadoop_env.sh</strong>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_211</span><br></pre></td></tr></table></figure><p>Configure <strong>core-site.xml</strong>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Configure <strong>hdfs-site.xml</strong>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.premissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Configure <strong>mapred-site.xml</strong>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Configure <strong>yarn-site.xml</strong>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>12288<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The following command is going to insert the name for all workers in lines:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/usr/hadoop/etc/hadoop$ vim workers</span><br></pre></td></tr></table></figure><p>Here is the content in workers file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure><h1 id="spark-environment-setup"><a class="markdownIt-Anchor" href="#spark-environment-setup"></a> Spark Environment Setup</h1><h2 id="install-spark"><a class="markdownIt-Anchor" href="#install-spark"></a> Install Spark</h2><ul><li>Version: <a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">Spark 2.4.3 (Binary)</a></li><li>Move Spark folder to /usr/hadoop/ folder</li><li>Change folder name into spark</li></ul><h2 id="add-pathes-into-path"><a class="markdownIt-Anchor" href="#add-pathes-into-path"></a> Add Pathes into $PATH</h2><p>Open the .bashrc file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ vim .bashrc</span><br></pre></td></tr></table></figure><p>In .bashrc file, insert the following lines:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/hadoop/spark</span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$SPARK_HOME</span>/python:<span class="variable">$PYTHONPATH</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON=<span class="string">"jupyter"</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON_OPTS=<span class="string">"notebook"</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=python3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:~/.<span class="built_in">local</span>/bin:<span class="variable">$SPARK_HOME</span></span><br></pre></td></tr></table></figure><p>Source the file to apply the changes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ <span class="built_in">source</span> .bashrc</span><br></pre></td></tr></table></figure><p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p><h2 id="configure-spark"><a class="markdownIt-Anchor" href="#configure-spark"></a> Configure Spark</h2><p>Configure the spark-defaults.conf file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change the template into actual file</span></span><br><span class="line">hadoop@master:/usr/hadoop/spark$ mv /conf/spark-defaults.conf.template /conf/spark-defaults.conf</span><br><span class="line">hadoop@master:/usr/hadoop/spark$ mv /conf/spark-env.template /conf/spark-env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Open and write file</span></span><br><span class="line">hadoop@master:/usr/hadoop$ vim spark/conf/spark-defaults.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">#Contents should be put into the file</span></span><br><span class="line">spark.master                     yarn</span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Create the log directory in HDFS</span></span><br><span class="line">hadoop@master:/usr/hadoop$ hdfs dfs -mkdir /spark-logs</span><br></pre></td></tr></table></figure><h2 id="checking-spark-version"><a class="markdownIt-Anchor" href="#checking-spark-version"></a> Checking Spark version</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:/usr/hadoop$ spark-shell –-version</span><br></pre></td></tr></table></figure><h1 id="setup-public-jupyter-notebook"><a class="markdownIt-Anchor" href="#setup-public-jupyter-notebook"></a> Setup Public Jupyter Notebook</h1><p>After the installation of jupyter:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ jupyter notebook --generate-config</span><br><span class="line">hadoop@master:~$ <span class="built_in">cd</span> .jupyter/</span><br><span class="line">hadoop@master:~/.jupyter/$ vim jupyter_notebook_config.py</span><br></pre></td></tr></table></figure><p>Uncomment lines and adjust some values:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip = <span class="string">'master'</span></span><br><span class="line">c.NotebookApp.port = 9999</span><br><span class="line">c.NotebookApp.allow_password_change = True</span><br></pre></td></tr></table></figure><p><strong><em>Notice: After the first change of the password and login please set allow_password_change into False or comment it out.</em></strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.allow_password_change = False</span><br></pre></td></tr></table></figure><h1 id="extras"><a class="markdownIt-Anchor" href="#extras"></a> Extras</h1><h2 id="change-machines-username"><a class="markdownIt-Anchor" href="#change-machines-username"></a> Change Machines’ Username</h2><p>The username should be all the same in different machines because when hadoop connects to other machines, it uses its username as default username for the other machines to connect each other.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Here should be the format for username@hostname on each machine</span></span><br><span class="line">hadoop@master</span><br><span class="line">hadoop@slave1</span><br><span class="line">hadoop@slave2</span><br><span class="line">hadoop@slave3</span><br></pre></td></tr></table></figure><p>If the username has been set wrong by mistake when installing the system, it needs changing by using the following commands:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ sudo passwd root</span><br><span class="line">hadoop@slave1:~$ su -</span><br><span class="line">root@slave1:~\<span class="comment"># usermod -l hadoop -d /home/hadoop -m slave1</span></span><br></pre></td></tr></table></figure><p><strong><em>Notice: These command can only run after logging into other user.  So, please create a new user and then logout the purpose user and login into the new user to type these command to change the purpose user’s username by typing the commands above to the new user’s terminal.</em></strong></p><h2 id="docker-suspended-not-in-use"><a class="markdownIt-Anchor" href="#docker-suspended-not-in-use"></a> Docker (<strong>Suspended</strong> - Not in use)</h2><p><a href="https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04" target="_blank" rel="noopener">Guide to Install Docker</a></p><p><a href="https://hub.docker.com/signup" target="_blank" rel="noopener">Sign Up Docker</a></p><p>Login Docker:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ sudo docker login</span><br><span class="line">hadoop@slave1:~$ mkdir images</span><br></pre></td></tr></table></figure><p><a href="https://hub.docker.com/r/sequenceiq/hadoop-docker/" target="_blank" rel="noopener">Guide to Use Hadoop Image</a></p><p>Pull -&gt; Run</p><h2 id="useful-commands"><a class="markdownIt-Anchor" href="#useful-commands"></a> Useful Commands</h2><h3 id="general-commands"><a class="markdownIt-Anchor" href="#general-commands"></a> General Commands</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Format the namenode - ONLY RUN ONCE</span></span><br><span class="line">hadoop@master:~$ hadoop namenode -format</span><br><span class="line"></span><br><span class="line"><span class="comment">#Start Service</span></span><br><span class="line">hadoop@master:~$ start-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Stop Service</span></span><br><span class="line">hadoop@master:~$ stop-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Get hdfs Report</span></span><br><span class="line">hadoop@master:~$ hdfs dfsadmin -report</span><br><span class="line"></span><br><span class="line"><span class="comment">#Copy Files to Remote Computer</span></span><br><span class="line">hadoop@slave1:~$ scp -r &lt;folder_name&gt; &lt;remote_username&gt;@&lt;remote_hostname&gt;:&lt;remote_path&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Change Permission for Remote Computer</span></span><br><span class="line">hadoop@slave1:~$ chown -R &lt;remote_username&gt;:&lt;remote_hostname&gt; &lt;folder_name&gt;</span><br></pre></td></tr></table></figure><h3 id="resetting-path-in-case-if-the-path-is-overwritten-by-mistake"><a class="markdownIt-Anchor" href="#resetting-path-in-case-if-the-path-is-overwritten-by-mistake"></a> Resetting $PATH (In case if the $PATH is overwritten by mistake)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="string">"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:"</span></span><br><span class="line">hadoop@slave1:/$ <span class="built_in">source</span> environment</span><br></pre></td></tr></table></figure><h1 id="references"><a class="markdownIt-Anchor" href="#references"></a> References</h1><h2 id="hadoop"><a class="markdownIt-Anchor" href="#hadoop"></a> Hadoop</h2><p><a href="https://www.tutorialspoint.com/hadoop/hadoop_enviornment_setup.htm" target="_blank" rel="noopener">Hadoop Environment Configeration</a></p><p><a href="https://www.cnblogs.com/lanxuezaipiao/p/3525554.html" target="_blank" rel="noopener">一步步教你Hadoop多节点集群安装配置</a></p><p><a href="https://chaoge123456.github.io/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.html/" target="_blank" rel="noopener">Hadoop分布式集群搭建</a></p><p><a href="https://blog.csdn.net/zolalad/article/details/11470449" target="_blank" rel="noopener">Hadoop系统完全分布式集群搭建方法</a></p><h2 id="java-jdk"><a class="markdownIt-Anchor" href="#java-jdk"></a> Java JDK</h2><p><a href="https://stackoverflow.com/questions/14788345/how-to-install-the-jdk-on-ubuntu-linux" target="_blank" rel="noopener">How to install the JDK on Ubuntu Linux (OpenJDK)</a></p><p><a href="https://www.baeldung.com/oracle-jdk-vs-openjdk" target="_blank" rel="noopener">Differences between OpenJDK and Oracle JDK</a></p><h2 id="spark"><a class="markdownIt-Anchor" href="#spark"></a> Spark</h2><p><a href="https://opensource.com/article/18/11/pyspark-jupyter-notebook" target="_blank" rel="noopener">How to set up PySpark for your Jupyter notebook</a></p><p><a href="http://www.techguru.my/programming/install-spark-2-3-x-on-yarn-with-hadoop-3-x/" target="_blank" rel="noopener">Install Spark 2.3.x on YARN with Hadoop 3.x</a></p><p><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener">RDD Programming Guide</a></p><h2 id="jupyter-notebook"><a class="markdownIt-Anchor" href="#jupyter-notebook"></a> Jupyter Notebook</h2><p><a href="https://jupyter-notebook.readthedocs.io/en/stable/public_server.html" target="_blank" rel="noopener">Tutorial on setting up public jupyter notebook</a></p><h2 id="hdfs"><a class="markdownIt-Anchor" href="#hdfs"></a> HDFS</h2><p><a href="http://fibrevillage.com/storage/630-using-hdfs-command-line-to-manage-files-and-directories-on-hadoop" target="_blank" rel="noopener">Using hdfs command line to manage files and directories on Hadoop</a></p><h2 id="docker"><a class="markdownIt-Anchor" href="#docker"></a> Docker</h2><p><a href="https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04" target="_blank" rel="noopener">How To Install Docker On Ubuntu</a></p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
          <category> Big Data </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Setup </tag>
            
            <tag> Environment </tag>
            
            <tag> Installation </tag>
            
            <tag> Configuration </tag>
            
            <tag> Big Data </tag>
            
            <tag> Data Science </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/08/16/hello-world/"/>
      <url>/2019/08/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2><h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
