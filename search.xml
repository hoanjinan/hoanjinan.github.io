<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Natural Language Processing (NLP)</title>
      <link href="/2019/09/02/Natural-Language-Processing/"/>
      <url>/2019/09/02/Natural-Language-Processing/</url>
      
        <content type="html"><![CDATA[<h1 id="introduction-to-the-post"><a class="markdownIt-Anchor" href="#introduction-to-the-post"></a> Introduction to The Post</h1><p>Have you ever wondered how your email filters out spam messages?  Or maybe how autocorrect on your phone knows what you’re trying to type?  In this post, we’ll cover some basics of natural language processing like reading in and creating structure in messy text data, and then cleaning and tokenizing that data.  Then the post will cover some of the more advanced topics like lemmatizing, stemming, and vectorizing the data.  In other words, converting it from text into a numeric matrix.  The post do this with a focus on preparing the data to build a machine learning classifier on top of it.  The post will also learn how to build two different types of machine learning models, while thoroughly testing and evaluating different variations of those models.  We’ll have the tools to go from messy dataset to concise and accurate predictions from machine learning model, to deliver solutions to complex business problems.</p><h1 id="introduction-to-natural-language-processing-nlp"><a class="markdownIt-Anchor" href="#introduction-to-natural-language-processing-nlp"></a> Introduction to Natural Language Processing (NLP)</h1><p>Natural language processing is a field concerned with the ability of a computer to understand, analyze, manipulate, and potentially generate human language. By human language, we’re simply referring to any language used for everyday communication.  This can be English, Spanish, French, anything like that.  Now it’s worth noting that Python doesn’t naturally know what any given word means.  All it will see is a string of characters.  For instance, it has no idea what natural actually means.  It sees that it’s seven characters long, but the individual characters don’t mean anything to Python and certainly the collection of those characters together don’t mean anything, either.  So we know that, what an N is, what an A is, and we know that together, those seven characters makes up the word natural, and we know what that means.  So NLP is the field of getting the computer to understand what naturally actually signifies, and from there we can get into the manipulation or potentially even generation of that human language.</p><p>You probably experience natural language processing on a daily basis.  They may not really even know it.  So here are a few examples that you may see on a day to day basis.  The first would be a spam filter, so this is just where your email server is determining whether an incoming email is spam or not, based on the content of the body, the subject, and maybe the email domain.  The second is auto-complete, where Google is basically predicting what you’re interested in searching for based on what you’ve already entered and what others commonly search for with those same phrases.  So if I search for natural language processing, it knows that many other people are interested in learning NLP with Python, or learning it through a course, or looking for jobs related to natural language processing.  So it can auto-complete your search for you.  The last is auto-correct, where say iPhone is trying to help you correct a misspelling. It shows how auto-correct has actually evolved over time and continues to evolve and learn by upgrading the operating system.  So with iOS 6, if you’re trying to say, “I’ll be ill tomorrow,” It wouldn’t necessarily correct I’ll be I’ll tomorrow until iOS 7, where it actually corrects, it auto-completes tomorrow and corrects I’ll into ill.  So it’ll correctly send as I’ll be ill tomorrow.  So that just kind of shows how NLP is still evolving and how a system like iOS is still kind of learning what natural language even means.</p><p>Now NLP is a very broad umbrella that encompasses many topics. A few of those might be sentiment analysis, topic modeling, text classification, and sentence segmentation or part-or-speech tagging.  The core component of natural language processing is extracting all the information from a block of text that is relevant to a computer understanding the language.  This is task specific, as well.  Different information is relevant for a sentiment analysis task than is relevant for a topic modeling task. So that’s a very quick introduction into what natural language processing is.</p><h1 id="introduction-to-nltk"><a class="markdownIt-Anchor" href="#introduction-to-nltk"></a> Introduction to NLTK</h1><p>The natural language toolkit is the most utilized package for handling natural language processing tasks in Python.  Usually called NLTK for short, it is a suite of open-source tools originally created in 2001 at the University of Pennsylvania for the purpose of making building NLP processes in Python easier.  This package has been expanded through the extensive contributions of open-source users in the years since its original development.  NLTK is great because it basically provides a jumpstart to building any NLP process by giving you the basic tools that you can then chain together to accomplish your goal rather than having to build all those tools from scratch and a lot of tools are packaged into NLTK.</p><h1 id="how-to-install-nltk-on-your-local-machine"><a class="markdownIt-Anchor" href="#how-to-install-nltk-on-your-local-machine"></a> How to install NLTK on your local machine</h1><p>Both sets of instructions below assume you already have Python installed. These instructions are taken directly from <a href="http://www.nltk.org/install.html" target="_blank" rel="noopener">http://www.nltk.org/install.html</a>.</p><p><strong>Mac/Unix</strong></p><p>From the terminal:</p><ol><li>Install NLTK: run <code>pip install -U nltk</code></li><li>Test installation: run <code>python</code> then type <code>import nltk</code></li></ol><p><strong>Windows</strong></p><ol><li>Install NLTK: <a href="http://pypi.python.org/pypi/nltk" target="_blank" rel="noopener">http://pypi.python.org/pypi/nltk</a></li><li>Test installation: <code>Start&gt;Python35</code>, then type <code>import nltk</code></li></ol><h2 id="download-nltk-data"><a class="markdownIt-Anchor" href="#download-nltk-data"></a> Download NLTK data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download()</span><br></pre></td></tr></table></figure><p>The following images will show the downloader of NLTK:</p><p><img alt="NLTK Uninstalled" data-src="/img/NLP/NLTK_Uninstalled.png" class="lozad"></p><p>In above image, select ‘all packages’ and click ‘download’ button to start installing all NLTK packages.</p><p><img alt="NLTK Installed" data-src="/img/NLP/NLTK_Installed.png" class="lozad"></p><p>The above image shows that all NLTK packages have been installed.</p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
          <category> Data Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Science </tag>
            
            <tag> Data Processing </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark for Machine Learning and AI</title>
      <link href="/2019/08/20/Spark-for-Machine-Learning-AI/"/>
      <url>/2019/08/20/Spark-for-Machine-Learning-AI/</url>
      
        <content type="html"><![CDATA[<h1 id="introduction-to-the-post"><a class="markdownIt-Anchor" href="#introduction-to-the-post"></a> Introduction to The Post</h1><p>This post is going to describe how to use the Apache Spark Platform for Machine Learning.  It will start by reviewing the basics of the dataframe data structure.  Then, it will cover the pre-processing to both numeric and text data so that is ready to use with Spark’s MLlib machine learning library.  The post will also describe multiple algorithms for clustering, classification and regression.  In the end, it will briefly describe a recommendation system.</p><h1 id="introduction-to-spark"><a class="markdownIt-Anchor" href="#introduction-to-spark"></a> Introduction to Spark</h1><p>Spark is a distributed, data processing platform for big data.  Distributed means Spark runs on a cluster of servers and the data processing means it performs computations such as ETL and modelling.  In the case of Spark, some of the most interesting computations are related to machine learning and data analysis.  Big data is a term broadly applied to data sets that are not easily analyzed on a single server or using older data management systems that were designed to run on a single server.  Spark is becoming increasingly polyglot with support for multiple languages.  Software engineers familiar with Scala and Java can use those languages while data scientists who prefer Python and R can work with those languages.</p><p>This post will use Python as programming language.  Spark uses a modular architecture that allows for multiple components or packages.  These include MLlib for machine learning, Spark SQL for relational querying, Spark Streaming for continuous processing of streaming data, and GraphX for graph analysis, such as social network analysis.  Spark is a generalized computation platform designed to manage large data sets.  It’s found use in a wide number of industries and applications, including real-time monitoring of financial data, text analysis related to competitive intelligence and compliance, analyzing how customers use eCommerce sites, and healthcare applications, such as analyzing genomes.</p><h1 id="steps-in-machine-learning-process"><a class="markdownIt-Anchor" href="#steps-in-machine-learning-process"></a> Steps in Machine Learning Process</h1><p>There are three broad steps in the machine learning process.</p><p>The first is preprocessing, which includes collecting, reformatting, and transforming data, so that it’s readily used by machine learning algorithms.</p><p>The second step is model building, in which machine learning algorithms are applied to training data to build models.  Models are pieces of code that capture the information implicit in training data.</p><p>The last step is validation, in which to measure how well models are performing.  There are multiple ways to measure performance.  The preprocessing phase includes extracting, transforming, and loading data.  This is similar to the ETL process used in business intelligence and data warehousing.</p><h1 id="creating-spark-session-and-basic-dataframe-processing"><a class="markdownIt-Anchor" href="#creating-spark-session-and-basic-dataframe-processing"></a> Creating Spark Session and Basic Dataframe Processing</h1><p>The following code is going to import all packages to use spark commands:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> to_timestamp</span><br></pre></td></tr></table></figure><h2 id="create-spark-session"><a class="markdownIt-Anchor" href="#create-spark-session"></a> Create Spark Session</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create Session</span></span><br><span class="line">spark = SparkSession.builder.master(<span class="string">'yarn'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Configure the Session</span></span><br><span class="line">spark.conf.set(<span class="string">"spark.executor.memory"</span>, <span class="string">"8g"</span>)</span><br><span class="line">spark.conf.set(<span class="string">'spark.executor.cores'</span>, <span class="string">'3'</span>)</span><br><span class="line">spark.conf.set(<span class="string">'spark.cores.max'</span>, <span class="string">'3'</span>)</span><br><span class="line">spark.conf.set(<span class="string">"spark.driver.memory"</span>,<span class="string">'8g'</span>)</span><br></pre></td></tr></table></figure><h2 id="basic-dataframe-processing"><a class="markdownIt-Anchor" href="#basic-dataframe-processing"></a> Basic Dataframe Processing</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the file path</span></span><br><span class="line">address = <span class="string">"hdfs://10.22.17.39:9000"</span></span><br><span class="line">sales_path = <span class="string">f"<span class="subst">&#123;address&#125;</span>/data/sales/"</span></span><br></pre></td></tr></table></figure><p>There are 3 ways to read csv files:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1st way to read csv file</span></span><br><span class="line">df = spark.read.csv(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2nd way to read csv file, similar to 3rd way</span></span><br><span class="line">df2 = spark.read.format(<span class="string">"csv"</span>).option(<span class="string">"header"</span>, <span class="string">"true"</span>).load(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3rd way to read csv file, similar to 2nd way</span></span><br><span class="line"><span class="comment"># Suggested way to read, many options to specify</span></span><br><span class="line">df3 = spark.read.load(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>,</span><br><span class="line">                     format=<span class="string">"csv"</span>, sep=<span class="string">"|"</span>, inferSchema=<span class="string">"true"</span>, header=<span class="string">"true"</span>, timestampFormat=<span class="string">"yyyy.MM.dd HH:mm:ss"</span>)</span><br></pre></td></tr></table></figure><p>Printing Schema:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Basic</span></span><br><span class="line">df</span><br><span class="line"></span><br><span class="line"><span class="comment"># A bit more details</span></span><br><span class="line">df.schema</span><br><span class="line">display(df3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># A more structured details</span></span><br><span class="line">df.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show data types for each columns</span></span><br><span class="line">df.dtypes</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show a summary of some calculated values like MAX, MIN, MEAN, COUNT for each column</span></span><br><span class="line">df.describe().show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Explain the physical plan for the dataframe</span></span><br><span class="line">df.explain()</span><br></pre></td></tr></table></figure><p>Getting Some Contents:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print column names</span></span><br><span class="line">df.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Showing the dataframe</span></span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Showing the first row in dataframe</span></span><br><span class="line">df.first()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get first 5 rows</span></span><br><span class="line">df.take(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Counting the number of rows</span></span><br><span class="line">df.count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Take only 10% of the data</span></span><br><span class="line">sample_df = df.sample(<span class="literal">False</span>, <span class="number">0.1</span>)</span><br><span class="line">sample_df.count()</span><br></pre></td></tr></table></figure><p>Basic Queries:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Filtering Contents</span></span><br><span class="line">emp_mgrs_df = df.filter(<span class="string">"salary &gt;= 100000"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Seleting Columns to Show</span></span><br><span class="line">emp_mgrs_df.select(<span class="string">"salary"</span>).show()</span><br></pre></td></tr></table></figure><p>A bit more advanced query examples:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select unique values within a column and sort it in ascending order</span></span><br><span class="line">df.select(<span class="string">"PRODUCT_KEY"</span>).distinct().orderBy(<span class="string">"PRODUCT_KEY"</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter the type and select some useful columns</span></span><br><span class="line">df.filter(df3[<span class="string">'TRANSACTION_TYPE_NAME'</span>] == <span class="string">'Item'</span>).select(<span class="string">'PRODUCT_KEY'</span>, <span class="string">'TRANSACTION_ID'</span>, <span class="string">'ORDER_NUM'</span>, <span class="string">'ITEM_QUANTITY_VAL'</span>, <span class="string">'ITEM_AMT'</span>, <span class="string">'ITEM_UNIT_PRICE_AMT'</span>, <span class="string">'TRANSACTION_DT'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select userful columns and group them by the keys, then calculate the sum of quantity for each key and sort it in a decending order.</span></span><br><span class="line">df.select(<span class="string">"PRODUCT_KEY"</span>, <span class="string">"ITEM_QUANTITY_VAL"</span>).groupBy(<span class="string">"PRODUCT_KEY"</span>).sum(<span class="string">"ITEM_QUANTITY_VAL"</span>).sort(<span class="string">"sum(ITEM_QUANTITY_VAL)"</span>, ascending = <span class="literal">False</span>).show()</span><br></pre></td></tr></table></figure><p>Some Useful Functions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This allow the programme to retrive the results from terminal</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_path</span><span class="params">(path)</span>:</span></span><br><span class="line">    arguments = <span class="string">"hdfs dfs -ls "</span>+ path +<span class="string">" | awk '&#123;print $8&#125;'"</span></span><br><span class="line">    proc = subprocess.Popen(arguments, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    s_output, s_err = proc.communicate()</span><br><span class="line">    all_files_path = s_output.decode(<span class="string">'utf-8'</span>).split()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> all_files_path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform date values and make some new columns to display</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_date_n_sales</span><span class="params">(dataframe)</span>:</span></span><br><span class="line">    filtered_sales = filter_sales(dataframe)</span><br><span class="line">    expand_date_n_sales = filtered_sales.select(<span class="string">"PRODUCT_KEY"</span>, <span class="string">"ITEM_QUANTITY_VAL"</span>, <span class="string">"TRANSACTION_DT"</span>,</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'Y'</span>).alias(<span class="string">'year'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'M'</span>).alias(<span class="string">'month'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'D'</span>).alias(<span class="string">'day'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'W'</span>).alias(<span class="string">'week_no'</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> expand_date_n_sales</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loop through all files to get the data and merge together</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_cleaned_sales</span><span class="params">(address, path)</span>:</span></span><br><span class="line">    all_files_path = get_path(path)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(all_files_path)):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            first_raw_df = load_data(address, all_files_path[i])</span><br><span class="line">            df = expand_date_n_sales(first_raw_df)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            raw_df = load_data(address, all_files_path[i])</span><br><span class="line">            tmp_df = expand_date_n_sales(raw_df)</span><br><span class="line">            df = df.union(tmp_df)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure><h1 id="components-of-spark-mllib"><a class="markdownIt-Anchor" href="#components-of-spark-mllib"></a> Components of Spark MLlib</h1><p>The MLlib package has three types of functions.</p><p>The first is machine learning algorithms.  The set of algorithms currently includes algorithms for classifications, which is for categorizing something, such as a customer likely to leave for a competitor.  Regression, which is used for predicting a numeric value like a home price.  Clustering is used to group similar items together.  Unlike classification, there are no predefined groups, so this is really useful when exploring data.  Finally, there’s topic modeling, which is a way to identify themes in a text.</p><p>The second group is workflows.  Workflow components help organize commonly used steps, like pre-processing operations and tuning.  This makes it easy to run a sequence of steps repeatedly while varying some parameters of the process.</p><p>Utilities are lower level functions that give you access to distributed linear algebra and statistics functions.</p><h1 id="introduction-to-preprocessing"><a class="markdownIt-Anchor" href="#introduction-to-preprocessing"></a> Introduction to Preprocessing</h1><p>There are two types of pre-processing, numeric and text pre-processing.</p><h2 id="numeric"><a class="markdownIt-Anchor" href="#numeric"></a> Numeric</h2><h3 id="normalisation-minmaxscaler"><a class="markdownIt-Anchor" href="#normalisation-minmaxscaler"></a> Normalisation (MinMaxScaler)</h3><p>Normalising maps data values from their original range to the range of zero to one.  It’s used to avoid problems when some attributes have large ranges and others have small ranges.  For example, salaries have a large range, but years of employment has a small range.</p><h3 id="standardisation-standardscaler"><a class="markdownIt-Anchor" href="#standardisation-standardscaler"></a> Standardisation (StandardScaler)</h3><p>Standardising maps data values from their original range to a range of negative one to one and it also has a mean value of zero.  This transformation creates a normal distribution with a standard deviation of one.  This transforms our data into a bell curve shape formation.  It’s used when attributes have different scales, and the machine learning algorithm you’re using assumes a normal distribution.</p><h3 id="partition-bucketiser"><a class="markdownIt-Anchor" href="#partition-bucketiser"></a> Partition (Bucketiser)</h3><p>Partitioning maps data values from continuous values to buckets, like histograms.  Deciles and percentiles are examples of buckets.  It’s useful when you want to work with groups of values instead of a continuous range of values.</p><h2 id="text"><a class="markdownIt-Anchor" href="#text"></a> Text</h2><h3 id="tokenisation-tokeniser"><a class="markdownIt-Anchor" href="#tokenisation-tokeniser"></a> Tokenisation (Tokeniser)</h3><p>This transformation maps text from a single string to a set of tokens, or words. For example, the sentence, quote, “This is a Sentence,” can be mapped into a list of tokens, or words, such as the four word list shown below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">"This"</span>, <span class="string">"is"</span>, <span class="string">"a"</span>, <span class="string">"sentence"</span>]</span><br></pre></td></tr></table></figure><h3 id="term-frequency-inverse-document-frequency-tf-idf-hashing-tf"><a class="markdownIt-Anchor" href="#term-frequency-inverse-document-frequency-tf-idf-hashing-tf"></a> Term Frequency Inverse Document Frequency (TF-IDF) - (Hashing TF)</h3><p>This method maps text from a single, typically long string, to a vector, indicating the frequency of each word in a text relative to a group of texts such as a corpus. This transformation is widely used in text classification.  TF-IDF captures the intuition that infrequently used words are more useful for distinguishing categories of text than frequently used words.</p><h1 id="introduction-to-clustering"><a class="markdownIt-Anchor" href="#introduction-to-clustering"></a> Introduction to Clustering</h1><p>Often when working with new data sets, it helps to explore the data and look for macro-level structures such as broad clusters of data.  Clustering algorithms group data into clusters that allow us to see how large data sets can break down into distinct subgroups.  K-means is widely used and works well for finding clusters in small and mid-sized data sets.  For large data sets, the Bisecting K-means algorithms can be faster.</p><h2 id="k-means-clustering"><a class="markdownIt-Anchor" href="#k-means-clustering"></a> K-means Clustering</h2><p><strong><em>Don’t forget to create a spark session before using spark!</em></strong></p><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br></pre></td></tr></table></figure><p>Create a dataframe:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cluster_df = spark.read.csv(<span class="string">"./ex/Ch03/03_02/clustering_dataset.csv"</span>, header = <span class="literal">True</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Select all 75 rows of data</span></span><br><span class="line">cluster_df.show(<span class="number">75</span>)</span><br></pre></td></tr></table></figure><p>Transform data to a feature vector:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(imputCols = [<span class="string">"col1"</span>, <span class="string">"col2"</span>, <span class="string">"col3"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">vcluster_df = vectorAssembler.transform(cluster_df)</span><br></pre></td></tr></table></figure><p>Setup K-means algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the cluster number</span></span><br><span class="line">kmeans = KMeans().setK(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set where the k-means algorithm starts</span></span><br><span class="line">kmeans = kmeans.setSeed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the data</span></span><br><span class="line">kmodel = kmeans.fit(vcluster_df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the centers of the clusters</span></span><br><span class="line">centers = kmodel.clusterCenters()</span><br><span class="line"></span><br><span class="line">centers</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">35.88461538</span>, <span class="number">31.46153846</span>, <span class="number">34.42307692</span>]),</span><br><span class="line"> array([<span class="number">5.12</span>, <span class="number">5.84</span>, <span class="number">4.84</span>]),</span><br><span class="line"> array([<span class="number">80.</span>        , <span class="number">79.20833333</span>, <span class="number">78.29166667</span>])]</span><br></pre></td></tr></table></figure><h2 id="hierarchical-clustering"><a class="markdownIt-Anchor" href="#hierarchical-clustering"></a> Hierarchical Clustering</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> BisectingKMeans</span><br></pre></td></tr></table></figure><p>Setup Bisecting KMeans algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bkmeans = BisectingKMeans().setK(<span class="number">3</span>)</span><br><span class="line">bkmeans = bkmeans.setSeed(<span class="number">1</span>)</span><br><span class="line">bkmodel = bkmeans.fit(vcluster_df)</span><br><span class="line">bkcenters = bkmodel.clusterCenters()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">5.12</span>, <span class="number">5.84</span>, <span class="number">4.84</span>]),</span><br><span class="line"> array([<span class="number">35.88461538</span>, <span class="number">31.46153846</span>, <span class="number">34.42307692</span>]),</span><br><span class="line"> array([<span class="number">80.</span>        , <span class="number">79.20833333</span>, <span class="number">78.29166667</span>])]</span><br></pre></td></tr></table></figure><h1 id="introduction-to-classification"><a class="markdownIt-Anchor" href="#introduction-to-classification"></a> Introduction to Classification</h1><p>Classification algorithms are useful when we have datasets that we want to be able to split into different categories.  So, for example, we might have a number of pieces of data that fall into Category A or Category B, and sometimes it’s not so obvious where certain things should fall.  Classification algorithms help us identify boundaries between different categories and make it easy for us to then decide how to assign a new entity to a particular category.</p><h2 id="preprocessing-the-iris-dataset"><a class="markdownIt-Anchor" href="#preprocessing-the-iris-dataset"></a> Preprocessing The Iris Dataset</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br></pre></td></tr></table></figure><p>Create A Spark Session:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder.master(<span class="string">'local'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br></pre></td></tr></table></figure><p>Create Spark Dataframe:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iris_df = spark.read.csv(<span class="string">"iris.data"</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line">iris_df.show()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+---+---+---+---+-----------+</span><br><span class="line">|_c0|_c1|_c2|_c3|        _c4|</span><br><span class="line">+---+---+---+---+-----------+</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.5</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.9</span>|<span class="number">3.0</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.7</span>|<span class="number">3.2</span>|<span class="number">1.3</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.6</span>|<span class="number">3.1</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.0</span>|<span class="number">3.6</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.9</span>|<span class="number">1.7</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.6</span>|<span class="number">3.4</span>|<span class="number">1.4</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.0</span>|<span class="number">3.4</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.4</span>|<span class="number">2.9</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.9</span>|<span class="number">3.1</span>|<span class="number">1.5</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.7</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.8</span>|<span class="number">3.4</span>|<span class="number">1.6</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.8</span>|<span class="number">3.0</span>|<span class="number">1.4</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.3</span>|<span class="number">3.0</span>|<span class="number">1.1</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.8</span>|<span class="number">4.0</span>|<span class="number">1.2</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.7</span>|<span class="number">4.4</span>|<span class="number">1.5</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.9</span>|<span class="number">1.3</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.5</span>|<span class="number">1.4</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.7</span>|<span class="number">3.8</span>|<span class="number">1.7</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.8</span>|<span class="number">1.5</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">+---+---+---+---+-----------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure><p>Rename all columns:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">iris_df = iris_df.select(col(<span class="string">"_c0"</span>).alias(<span class="string">"sepal_length"</span>),</span><br><span class="line">                         col(<span class="string">"_c1"</span>).alias(<span class="string">"sepal_width"</span>),</span><br><span class="line">                         col(<span class="string">"_c2"</span>).alias(<span class="string">"petal_length"</span>),</span><br><span class="line">                         col(<span class="string">"_c3"</span>).alias(<span class="string">"petal_width"</span>),</span><br><span class="line">                         col(<span class="string">"_c4"</span>).alias(<span class="string">"species"</span>)</span><br><span class="line">                        )</span><br><span class="line"></span><br><span class="line">iris_df.show()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+</span><br></pre></td></tr></table></figure><p>Transform the dataframe into vector structure:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(inputCols = [<span class="string">"sepal_length"</span>, <span class="string">"sepal_width"</span>, <span class="string">"petal_length"</span>, <span class="string">"petal_width"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">viris_df = vectorAssembler.transform(iris_df)</span><br><span class="line"></span><br><span class="line">viris_df.show()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|         features|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.7</span>,<span class="number">3.2</span>,<span class="number">1.3</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.6</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.7</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.4</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.4</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.4</span>,<span class="number">2.9</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.7</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.4</span>,<span class="number">1.6</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.3</span>,<span class="number">3.0</span>,<span class="number">1.1</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.8</span>,<span class="number">4.0</span>,<span class="number">1.2</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">4.4</span>,<span class="number">1.5</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.3</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">3.8</span>,<span class="number">1.7</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.8</span>,<span class="number">1.5</span>,<span class="number">0.3</span>]|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br></pre></td></tr></table></figure><p>Convert string value of species into numeric values:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">indexer = StringIndexer(inputCol = <span class="string">"species"</span>, outputCol = <span class="string">"label"</span>)</span><br><span class="line">iviris_df = indexer.fit(viris_df).transform(viris_df)</span><br><span class="line"></span><br><span class="line">iviris_df.show()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|         features|label|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.7</span>,<span class="number">3.2</span>,<span class="number">1.3</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.6</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.7</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.4</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.4</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.4</span>,<span class="number">2.9</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.7</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.4</span>,<span class="number">1.6</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.3</span>,<span class="number">3.0</span>,<span class="number">1.1</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.8</span>,<span class="number">4.0</span>,<span class="number">1.2</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">4.4</span>,<span class="number">1.5</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.3</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">3.8</span>,<span class="number">1.7</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.8</span>,<span class="number">1.5</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br></pre></td></tr></table></figure><h2 id="naive-bayes-classification"><a class="markdownIt-Anchor" href="#naive-bayes-classification"></a> Naive Bayes Classification</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> NaiveBayes</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br></pre></td></tr></table></figure><p>Split the dataset into train and test datasets:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">splits = iviris_df.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>], <span class="number">1</span>)</span><br><span class="line">train_df = splits[<span class="number">0</span>]</span><br><span class="line">test_df = splits[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>Train the model using Naive Bayes Classifier and make the prediction:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nb = NaiveBayes(modelType = <span class="string">"multinomial"</span>)</span><br><span class="line">nbmodel = nb.fit(train_df)</span><br><span class="line"></span><br><span class="line">predictions_df = nbmodel.transform(test_df)</span><br><span class="line">predictions_df.take(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Row(sepal_length=<span class="number">4.5</span>, sepal_width=<span class="number">2.3</span>, petal_length=<span class="number">1.3</span>, petal_width=<span class="number">0.3</span>, species=<span class="string">'Iris-setosa'</span>, features=DenseVector([<span class="number">4.5</span>, <span class="number">2.3</span>, <span class="number">1.3</span>, <span class="number">0.3</span>]), label=<span class="number">0.0</span>, rawPrediction=DenseVector([<span class="number">-10.3605</span>, <span class="number">-11.0141</span>, <span class="number">-11.7112</span>]), probability=DenseVector([<span class="number">0.562</span>, <span class="number">0.2924</span>, <span class="number">0.1456</span>]), prediction=<span class="number">0.0</span>)]</span><br></pre></td></tr></table></figure><p>Evaluate the accuracy:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">evaluator = MulticlassClassificationEvaluator(labelCol = <span class="string">"label"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">nbaccuarcy = evaluator.evaluate(predictions_df)</span><br><span class="line"></span><br><span class="line">nbaccuarcy</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.5862068965517241</span></span><br></pre></td></tr></table></figure><h2 id="multilayer-perceptron-classification"><a class="markdownIt-Anchor" href="#multilayer-perceptron-classification"></a> Multilayer Perceptron Classification</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> MultilayerPerceptronClassifier</span><br></pre></td></tr></table></figure><p>Set the layers and do some training using Multilayer Perceptron Classifier as well as making predictions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Have 4 layers multilayer perceptron,</span></span><br><span class="line"><span class="comment"># the input is 4 neurons, two hidden layers are 5 neurons each and output layer has 3 neurons</span></span><br><span class="line">layers = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">mlp = MultilayerPerceptronClassifier(layers = layers, seed = <span class="number">1</span>)</span><br><span class="line">mlp_model = mlp.fit(train_df)</span><br><span class="line">mlp_predictions = mlp_model.transform(test_df)</span><br></pre></td></tr></table></figure><p>Evaluate the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mlp_evaluator = MulticlassClassificationEvaluator(metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">mlp_accuracy = mlp_evaluator.evaluate(mlp_predictions)</span><br><span class="line"></span><br><span class="line">mlp_accuracy</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.9482758620689655</span></span><br></pre></td></tr></table></figure><h2 id="decision-trees-classification"><a class="markdownIt-Anchor" href="#decision-trees-classification"></a> Decision Trees Classification</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> DecisionTreeClassifier</span><br></pre></td></tr></table></figure><p>Train the model using Decision Trees Claccifier as well as making predictions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(labelCol = <span class="string">"label"</span>, featuresCol = <span class="string">"features"</span>)</span><br><span class="line">dt_model = dt.fit(train_df)</span><br><span class="line"></span><br><span class="line">dt_predictions = dt_model.transform(test_df)</span><br></pre></td></tr></table></figure><p>Evaluate the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt_evaluator = MulticlassClassificationEvaluator(labelCol = <span class="string">"label"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">dt_accuracy = dt_evaluator.evaluate(dt_predictions)</span><br><span class="line"></span><br><span class="line">dt_accuracy</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.9310344827586207</span></span><br></pre></td></tr></table></figure><h1 id="introduction-to-regresssion"><a class="markdownIt-Anchor" href="#introduction-to-regresssion"></a> Introduction to Regresssion</h1><p>Regression techniques allow us to make predictions about numeric values.  For example, if we have a product and the price of that product has been steadily rising over time, we might want to be able to estimate what the price will be in the future.  Now we could look at prices over a period of time and try and fit a line to those price points over time.  That line is useful because it goes out into the future and we can use it to make projections about what the price might be at some future point.</p><h2 id="pre-processing-the-dataset"><a class="markdownIt-Anchor" href="#pre-processing-the-dataset"></a> Pre-processing The Dataset</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br></pre></td></tr></table></figure><p>Create a spark session:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder.master(<span class="string">'local'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br></pre></td></tr></table></figure><p>Read the CSV file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pp_df = spark.read.csv(<span class="string">"power_plant.csv"</span>)</span><br><span class="line">pp_df</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]</span><br></pre></td></tr></table></figure><p>Read the CSV file again correctly:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pp_df = spark.read.csv(<span class="string">"power_plant.csv"</span>, header = <span class="literal">True</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line">pp_df</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[AT: double, V: double, AP: double, RH: double, PE: double]</span><br></pre></td></tr></table></figure><p>Creating a feature vector:</p><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(inputCols = [<span class="string">"AT"</span>, <span class="string">"V"</span>, <span class="string">"AP"</span>, <span class="string">"RH"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">vpp_df = vectorAssembler.transform(pp_df)</span><br><span class="line"></span><br><span class="line">vpp_df.take(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Row(AT=<span class="number">14.96</span>, V=<span class="number">41.76</span>, AP=<span class="number">1024.07</span>, RH=<span class="number">73.17</span>, PE=<span class="number">463.26</span>, features=DenseVector([<span class="number">14.96</span>, <span class="number">41.76</span>, <span class="number">1024.07</span>, <span class="number">73.17</span>]))]</span><br></pre></td></tr></table></figure><h2 id="linear-regression"><a class="markdownIt-Anchor" href="#linear-regression"></a> Linear Regression</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> LinearRegression</span><br></pre></td></tr></table></figure><p>Train the model using Linear Regression:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">lr_model = lr.fit(vpp_df)</span><br></pre></td></tr></table></figure><p>Coefficients:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.coefficients</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DenseVector([<span class="number">-1.9775</span>, <span class="number">-0.2339</span>, <span class="number">0.0621</span>, <span class="number">-0.1581</span>])</span><br></pre></td></tr></table></figure><p>Intercept:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.intercept</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">454.6092744523414</span></span><br></pre></td></tr></table></figure><p>Root Mean Squared Error:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.summary.rootMeanSquaredError</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4.557126016749488</span></span><br></pre></td></tr></table></figure><p>Save the model:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.save(<span class="string">"lr1.model"</span>)</span><br></pre></td></tr></table></figure><h2 id="decision-tree-regression"><a class="markdownIt-Anchor" href="#decision-tree-regression"></a> Decision Tree Regression</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br></pre></td></tr></table></figure><p>Split the dataset into train and test dataset:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">splits = vpp_df.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line">train_df = splits[<span class="number">0</span>]</span><br><span class="line">test_df = splits[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>Train the model and make the predictions using Decision Tree Regression:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeRegressor(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">dt_model = dt.fit(train_df)</span><br><span class="line"></span><br><span class="line">dt_predictions = dt_model.transform(test_df)</span><br></pre></td></tr></table></figure><p>Evaluate the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt_evaluator = RegressionEvaluator(labelCol = <span class="string">"PE"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"rmse"</span>)</span><br><span class="line">rmse = dt_evaluator.evaluate(dt_predictions)</span><br><span class="line"></span><br><span class="line">rmse</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4.459494278528065</span></span><br></pre></td></tr></table></figure><h2 id="gradient-boosted-tree-regression"><a class="markdownIt-Anchor" href="#gradient-boosted-tree-regression"></a> Gradient-boosted Tree Regression</h2><p>Import some essential spark packages:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> GBTRegressor</span><br></pre></td></tr></table></figure><p>Train the model and make the predictions using Gradient-boosted Tree Regression:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gbt = GBTRegressor(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">gbt_model = gbt.fit(train_df)</span><br><span class="line"></span><br><span class="line">gbt_predictions = gbt_model.transform(test_df)</span><br></pre></td></tr></table></figure><p>Evaluate the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gbt_evaluator = RegressionEvaluator(labelCol = <span class="string">"PE"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"rmse"</span>)</span><br><span class="line">gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)</span><br><span class="line"></span><br><span class="line">gbt_rmse</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3.976988494544201</span></span><br></pre></td></tr></table></figure><h1 id="understand-recommendation-systems"><a class="markdownIt-Anchor" href="#understand-recommendation-systems"></a> Understand Recommendation Systems</h1><p>A common problem in machine learning is making recommendations.  There’s two general ways of doing this.  One is called Collaborative Filtering. Let’s imagine you run an online bookstore, and you have a number of customers.  And these customers all like reading both the brown book and the red book.  Now a new customer comes along and indicates that they really enjoyed reading the red book.  What other books can we recommend to them? Definitely the brown book, since other people who have read the red book also enjoy reading the brown book.  This is an example of collaborative filtering.  Another way to make recommendations is based on the properties of the items that you’re working with. For example, if we have a customer who really enjoys readying Sci-fi, we might want to recommend other science fiction books to them, but not necessarily biographies.  Spark MLlib supports Collaborative Filtering, and it works by filling in something known as the user-item matrix.  So we can think of users as customers and items as books.  In this example below, we have a customer who likes item one and two and item four.  User number two, or customer number two, also likes item two and also likes item three.  Now, we’ll notice that user four has something in common with both user one and user three.  That means we probably want to recommend item two to user four.  This is an example of collaborative filtering.  This is the type of recommendation system that Spark MLlib supports.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+-----+-----+-----+-----+-----+</span><br><span class="line">|     |Item1|Item2|Item3|Item4|</span><br><span class="line">+-----+-----+-----+-----+-----+</span><br><span class="line">|User1|  x  |  x  |     |  x  |</span><br><span class="line">|User1|     |  x  |  x  |     |</span><br><span class="line">|User1|     |     |     |  x  |</span><br><span class="line">|User1|  x  |  ?  |  x  |     |</span><br><span class="line">+-----+-----+-----+-----+-----+</span><br></pre></td></tr></table></figure><h2 id="collaborative-filtering"><a class="markdownIt-Anchor" href="#collaborative-filtering"></a> Collaborative Filtering</h2><p>Collaborative filtering follows the same patterns we’ve used repeatedly in this post.</p><p>First we start with preprocessing.  We’re going to use the alternating least squares method that’s provided by Spark MLlib, and, to use that, we just import the ALS code from pyspark.ml.recommendation package.  And then we build a DataFrame using user-item ratings.</p><p>When it comes to modeling, we create an ALS object and, when we do that, we have to specify the user, the item, and the rating columns in our data frames.  And then we train the model using fit and fit is part of the ALS project.  And then when it’s time to evaluate, we create predictions using the transform of the ALS model and we apply that to our test data.  We create a RegressionEvaluator object and we use the evaluate function of that RegressionEvaluator object to calculate the root mean squared error, and that’ll give us a measure of how well our collaborative filtering is making recommendations.</p><h1 id="tips-for-using-spark-mllib"><a class="markdownIt-Anchor" href="#tips-for-using-spark-mllib"></a> Tips for Using Spark MLlib</h1><p>Let’s review some tips for working with Spark MLlib.</p><p>There are three basic stages of building machine learning models.  There’s a pre-processing phase where we collect, reformat, and transform the data.  And once we have that data, we can build our models using a variety of machine learning algorithms.  And then we want to make sure we evaluate our data to assess the quality of the models we built.</p><p>With that framework in mind, let’s look at some tips to make each of these stages go smoothly. First, when we’re pre-processing, we want to first load our data into DataFrames.  If you’re working with text files, it helps to have headers or column names in the text file.  When you read a file, make sure you use the inferSchema = True option.  That’ll make sure that things like dates and numeric values get mapped to their appropriate data type.  Use the VectorAssembler to create feature vectors and the StringIndexer to map from strings to numeric indexes.</p><p>During the model building phase, make sure to split your data into training and test sets. We use the training data to fit our models and then the test data to apply transformations to create predictions.  When we’re done building the model, we want to validate them.  I recommend using the MLlib evaluators.  The two that we looked at were the MulticlassClassificationEvaluator and the RegressionEvaluator.  Just be sure to use the right one for the kind of algorithm you’re working with.  Also, be sure to experiment with multiple algorithms.  Once you’ve gone through the pre-processing phase, it’s very easy to test other algorithms so take advantage of that.  Also, vary hyperparameters for the algorithms you’re working with.  Sometimes you can get slightly better performance just by changing a hyperparameter.</p><p>Where do we go from here? Well first I’d recommend consulting the MLlib documentation.  It’s really high quality documentation and it provides details on the APIs and includes extensive examples.  When you’re ready to work with other data sets, look at the Kaggle website that has both machine learning data sets and articles about machine learning.  Now Spark is designed for working with big data so if you’re ready to work with machine learning at big data scales, consult the AWS data sets.  These are public data sets that are freely available from the AWS cloud service.  Spark and MLlib are both under active development. So as you go forward working with MLlib, be sure to check back at the Spark MLlib website for updates and new features.</p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
          <category> Big Data </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Big Data </tag>
            
            <tag> Data Science </tag>
            
            <tag> Data Processing </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> AI </tag>
            
            <tag> Model </tag>
            
            <tag> Query </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop Environment Setup</title>
      <link href="/2019/08/19/Hadoop-Environment-Setup/"/>
      <url>/2019/08/19/Hadoop-Environment-Setup/</url>
      
        <content type="html"><![CDATA[<h1 id="ubuntu-installation"><a class="markdownIt-Anchor" href="#ubuntu-installation"></a> Ubuntu Installation</h1><h2 id="version-ubuntu-desktop-18042-lts"><a class="markdownIt-Anchor" href="#version-ubuntu-desktop-18042-lts"></a> Version: <a href="https://ubuntu.com/download/desktop" target="_blank" rel="noopener">Ubuntu Desktop 18.04.2 LTS</a></h2><h2 id="installation-tutorial-install-ubuntu-desktop"><a class="markdownIt-Anchor" href="#installation-tutorial-install-ubuntu-desktop"></a> Installation Tutorial: <a href="https://tutorials.ubuntu.com/tutorial/tutorial-install-ubuntu-desktop#0" target="_blank" rel="noopener">Install Ubuntu Desktop</a></h2><h2 id="disable-auto-update"><a class="markdownIt-Anchor" href="#disable-auto-update"></a> Disable Auto Update</h2><h2 id="disable-auto-shut-down-and-sleep"><a class="markdownIt-Anchor" href="#disable-auto-shut-down-and-sleep"></a> Disable Auto Shut Down and Sleep</h2><p><strong><em>Notice: In log in details session, please set your computer’s name as master/slave1/slave2/slave3 and set username as hadoop across all machines.</em></strong></p><h1 id="hadoop-environment-setup"><a class="markdownIt-Anchor" href="#hadoop-environment-setup"></a> Hadoop Environment Setup</h1><h2 id="pre-installation-setup"><a class="markdownIt-Anchor" href="#pre-installation-setup"></a> Pre-installation Setup</h2><h3 id="checking-hostname"><a class="markdownIt-Anchor" href="#checking-hostname"></a> Checking Hostname</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ hostname</span><br><span class="line">slave1</span><br></pre></td></tr></table></figure><h3 id="checking-current-ip-address"><a class="markdownIt-Anchor" href="#checking-current-ip-address"></a> Checking Current IP Address</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ hostname -I</span><br><span class="line">10.22.16.84 172.17.0.1</span><br></pre></td></tr></table></figure><h3 id="install-vim"><a class="markdownIt-Anchor" href="#install-vim"></a> Install vim</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /</span><br><span class="line">hadoop@slave1:/$ <span class="built_in">cd</span> etc</span><br><span class="line">hadoop@slave1:/etc$ sudo apt install vim</span><br></pre></td></tr></table></figure><h3 id="add-ip-addresses"><a class="markdownIt-Anchor" href="#add-ip-addresses"></a> Add IP Addresses</h3><p>Insert the information from the table below into /etc/hosts file.</p><table><thead><tr><th>IP Addresses</th><th>Hostnames</th></tr></thead><tbody><tr><td>10.22.17.39</td><td>master</td></tr><tr><td>10.22.16.84</td><td>slave1</td></tr><tr><td>10.22.17.150</td><td>slave2</td></tr><tr><td>10.22.17.79</td><td>slave3</td></tr></tbody></table><p>Command to open and insert information:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/etc$ sudo vim hosts</span><br></pre></td></tr></table></figure><p>Check if connections to other machines can be established:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/etc$ ping master</span><br></pre></td></tr></table></figure><h2 id="java-jdk-installation"><a class="markdownIt-Anchor" href="#java-jdk-installation"></a> Java JDK Installation</h2><h3 id="version-java-se-development-kit-8u221-requires-registration"><a class="markdownIt-Anchor" href="#version-java-se-development-kit-8u221-requires-registration"></a> Version: <a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">Java SE Development Kit 8u221</a> (Requires Registration)</h3><h3 id="extract-the-files-to-usrlibjvm"><a class="markdownIt-Anchor" href="#extract-the-files-to-usrlibjvm"></a> Extract the Files to /usr/lib/jvm/</h3><h3 id="add-javas-path-into-path"><a class="markdownIt-Anchor" href="#add-javas-path-into-path"></a> Add Java’s Path into $PATH</h3><p>Open /etc/profile file to write the Java path into:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /etc</span><br><span class="line">hadoop@slave1:~$ sudo vim profile</span><br></pre></td></tr></table></figure><p>Insert the following code into the file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_211</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$CLASSPATH</span>:<span class="variable">$JAVA_HOME</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure><p>Source the file to apply the changes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">source</span> profile</span><br></pre></td></tr></table></figure><p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p><h3 id="check-java-version-and-path"><a class="markdownIt-Anchor" href="#check-java-version-and-path"></a> Check Java Version and Path</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ java -version</span><br><span class="line">java version <span class="string">"1.8.0_211"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_211-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)</span><br><span class="line">hadoop@slave1:~$ <span class="built_in">which</span> java</span><br><span class="line">/usr/lib/jvm/jdk1.8.0_211/bin/java</span><br></pre></td></tr></table></figure><h2 id="setup-ssh"><a class="markdownIt-Anchor" href="#setup-ssh"></a> Setup SSH</h2><p>Setting up this to allow the machines to connect each other without entering passwords.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Installing SSH</span></span><br><span class="line">hadoop@slave1:~$ sudo apt-get install openssh-server</span><br><span class="line"></span><br><span class="line"><span class="comment">#Generate a SSH key</span></span><br><span class="line">hadoop@slave1:~$ ssh-keygen -t rsa</span><br><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> .ssh/</span><br><span class="line"></span><br><span class="line"><span class="comment">#Copy key into authorized_keys file</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment">#To set the file that the owner can read and write on it</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ chmod 0600 authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment">#Configer settings on sshd_config file</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ sudo vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p>Type these lines in the end of the sshd_config file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RSAAuthentication yes</span><br><span class="line">PubkeyAuthentication yes</span><br><span class="line">AuthorizedKeysFile      %h/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p>Restarting the SSH service and copy its ssh id to other machines:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~/.ssh/$ service ssh restart</span><br><span class="line">hadoop@slave1:~/.ssh/$ ssh-copy-id master@master</span><br><span class="line">hadoop@slave1:~/.ssh/$ ssh <span class="string">'master@master'</span></span><br></pre></td></tr></table></figure><h2 id="hadoop-installation"><a class="markdownIt-Anchor" href="#hadoop-installation"></a> Hadoop Installation</h2><h3 id="install-hadoop"><a class="markdownIt-Anchor" href="#install-hadoop"></a> Install Hadoop</h3><ul><li>Version: <a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz" target="_blank" rel="noopener">Hadoop 3.1.2 (Binary)</a></li><li>Move Hadoop folder to /usr/ folder</li><li>Change folder name into hadoop</li><li>Make tmp folder inside of the hadoop folder</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/$ sudo mv hadoop-3.1.2/ /usr/</span><br><span class="line">hadoop@slave1:/$ <span class="built_in">cd</span> usr/</span><br><span class="line">hadoop@slave1:/usr$ sudo mv hadoop-3.1.2/ hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#This line is going to give the permission to the user</span></span><br><span class="line">hadoop@slave1:/usr$ chown -R hadoop:slave1 hadoop/</span><br><span class="line">hadoop@slave1:/usr$ <span class="built_in">cd</span> hadoop/</span><br><span class="line">hadoop@slave1:/usr/hadoop$ mkdir tmp</span><br></pre></td></tr></table></figure><h3 id="add-hadoops-path-into-path"><a class="markdownIt-Anchor" href="#add-hadoops-path-into-path"></a> Add Hadoop’s Path into $PATH</h3><p>Open /etc/profile file to write the Hadoop path into:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /etc</span><br><span class="line">hadoop@slave1:~$ sudo vim profile</span><br></pre></td></tr></table></figure><p>Insert the following code into the file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure><p>Source the file to apply the changes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">source</span> profile</span><br></pre></td></tr></table></figure><p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p><h3 id="configure-hadoop"><a class="markdownIt-Anchor" href="#configure-hadoop"></a> Configure Hadoop</h3><p>Change configeration settings in 5 following files:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Finding the paths on each file</span></span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name hadoop-env.sh</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name core-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name hdfs-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name mapred-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name yarn-site.xml</span><br></pre></td></tr></table></figure><p>5 paths:</p><ul><li><a href="http://hadoop-env.sh" target="_blank" rel="noopener">hadoop-env.sh</a> - hadoop/etc/hadoop/hadoop-env.sh</li><li>core-site.xml - hadoop/etc/hadoop/core-site.xml</li><li>hdfs-site.xml - hadoop/etc/hadoop/hdfs-site.xml</li><li>mapred-site.xml - hadoop/etc/hadoop/mapred-site.xml</li><li>yarn-site.xml - hadoop/etc/hadoop/yarn-site.xml</li></ul><p>Configure <strong>hadoop_env.sh</strong>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_211</span><br></pre></td></tr></table></figure><p>Configure <strong>core-site.xml</strong>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Configure <strong>hdfs-site.xml</strong>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.premissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Configure <strong>mapred-site.xml</strong>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Configure <strong>yarn-site.xml</strong>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>12288<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The following command is going to insert the name for all workers in lines:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/usr/hadoop/etc/hadoop$ vim workers</span><br></pre></td></tr></table></figure><p>Here is the content in workers file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure><h1 id="spark-environment-setup"><a class="markdownIt-Anchor" href="#spark-environment-setup"></a> Spark Environment Setup</h1><h2 id="install-spark"><a class="markdownIt-Anchor" href="#install-spark"></a> Install Spark</h2><ul><li>Version: <a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">Spark 2.4.3 (Binary)</a></li><li>Move Spark folder to /usr/hadoop/ folder</li><li>Change folder name into spark</li></ul><h2 id="add-pathes-into-path"><a class="markdownIt-Anchor" href="#add-pathes-into-path"></a> Add Pathes into $PATH</h2><p>Open the .bashrc file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ vim .bashrc</span><br></pre></td></tr></table></figure><p>In .bashrc file, insert the following lines:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/hadoop/spark</span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$SPARK_HOME</span>/python:<span class="variable">$PYTHONPATH</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON=<span class="string">"jupyter"</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON_OPTS=<span class="string">"notebook"</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=python3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:~/.<span class="built_in">local</span>/bin:<span class="variable">$SPARK_HOME</span></span><br></pre></td></tr></table></figure><p>Source the file to apply the changes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ <span class="built_in">source</span> .bashrc</span><br></pre></td></tr></table></figure><p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p><h2 id="configure-spark"><a class="markdownIt-Anchor" href="#configure-spark"></a> Configure Spark</h2><p>Configure the spark-defaults.conf file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change the template into actual file</span></span><br><span class="line">hadoop@master:/usr/hadoop/spark$ mv /conf/spark-defaults.conf.template /conf/spark-defaults.conf</span><br><span class="line">hadoop@master:/usr/hadoop/spark$ mv /conf/spark-env.template /conf/spark-env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Open and write file</span></span><br><span class="line">hadoop@master:/usr/hadoop$ vim spark/conf/spark-defaults.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">#Contents should be put into the file</span></span><br><span class="line">spark.master                     yarn</span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Create the log directory in HDFS</span></span><br><span class="line">hadoop@master:/usr/hadoop$ hdfs dfs -mkdir /spark-logs</span><br></pre></td></tr></table></figure><h2 id="checking-spark-version"><a class="markdownIt-Anchor" href="#checking-spark-version"></a> Checking Spark version</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:/usr/hadoop$ spark-shell –-version</span><br></pre></td></tr></table></figure><h1 id="setup-public-jupyter-notebook"><a class="markdownIt-Anchor" href="#setup-public-jupyter-notebook"></a> Setup Public Jupyter Notebook</h1><p>After the installation of jupyter:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ jupyter notebook --generate-config</span><br><span class="line">hadoop@master:~$ <span class="built_in">cd</span> .jupyter/</span><br><span class="line">hadoop@master:~/.jupyter/$ vim jupyter_notebook_config.py</span><br></pre></td></tr></table></figure><p>Uncomment lines and adjust some values:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip = <span class="string">'master'</span></span><br><span class="line">c.NotebookApp.port = 9999</span><br><span class="line">c.NotebookApp.allow_password_change = True</span><br></pre></td></tr></table></figure><p><strong><em>Notice: After the first change of the password and login please set allow_password_change into False or comment it out.</em></strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.allow_password_change = False</span><br></pre></td></tr></table></figure><h1 id="extras"><a class="markdownIt-Anchor" href="#extras"></a> Extras</h1><h2 id="change-machines-username"><a class="markdownIt-Anchor" href="#change-machines-username"></a> Change Machines’ Username</h2><p>The username should be all the same in different machines because when hadoop connects to other machines, it uses its username as default username for the other machines to connect each other.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Here should be the format for username@hostname on each machine</span></span><br><span class="line">hadoop@master</span><br><span class="line">hadoop@slave1</span><br><span class="line">hadoop@slave2</span><br><span class="line">hadoop@slave3</span><br></pre></td></tr></table></figure><p>If the username has been set wrong by mistake when installing the system, it needs changing by using the following commands:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ sudo passwd root</span><br><span class="line">hadoop@slave1:~$ su -</span><br><span class="line">root@slave1:~\<span class="comment"># usermod -l hadoop -d /home/hadoop -m slave1</span></span><br></pre></td></tr></table></figure><p><strong><em>Notice: These command can only run after logging into other user.  So, please create a new user and then logout the purpose user and login into the new user to type these command to change the purpose user’s username by typing the commands above to the new user’s terminal.</em></strong></p><h2 id="docker-suspended-not-in-use"><a class="markdownIt-Anchor" href="#docker-suspended-not-in-use"></a> Docker (<strong>Suspended</strong> - Not in use)</h2><p><a href="https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04" target="_blank" rel="noopener">Guide to Install Docker</a></p><p><a href="https://hub.docker.com/signup" target="_blank" rel="noopener">Sign Up Docker</a></p><p>Login Docker:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ sudo docker login</span><br><span class="line">hadoop@slave1:~$ mkdir images</span><br></pre></td></tr></table></figure><p><a href="https://hub.docker.com/r/sequenceiq/hadoop-docker/" target="_blank" rel="noopener">Guide to Use Hadoop Image</a></p><p>Pull -&gt; Run</p><h2 id="useful-commands"><a class="markdownIt-Anchor" href="#useful-commands"></a> Useful Commands</h2><h3 id="general-commands"><a class="markdownIt-Anchor" href="#general-commands"></a> General Commands</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Format the namenode - ONLY RUN ONCE</span></span><br><span class="line">hadoop@master:~$ hadoop namenode -format</span><br><span class="line"></span><br><span class="line"><span class="comment">#Start Service</span></span><br><span class="line">hadoop@master:~$ start-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Stop Service</span></span><br><span class="line">hadoop@master:~$ stop-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Get hdfs Report</span></span><br><span class="line">hadoop@master:~$ hdfs dfsadmin -report</span><br><span class="line"></span><br><span class="line"><span class="comment">#Copy Files to Remote Computer</span></span><br><span class="line">hadoop@slave1:~$ scp -r &lt;folder_name&gt; &lt;remote_username&gt;@&lt;remote_hostname&gt;:&lt;remote_path&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Change Permission for Remote Computer</span></span><br><span class="line">hadoop@slave1:~$ chown -R &lt;remote_username&gt;:&lt;remote_hostname&gt; &lt;folder_name&gt;</span><br></pre></td></tr></table></figure><h3 id="resetting-path-in-case-if-the-path-is-overwritten-by-mistake"><a class="markdownIt-Anchor" href="#resetting-path-in-case-if-the-path-is-overwritten-by-mistake"></a> Resetting $PATH (In case if the $PATH is overwritten by mistake)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="string">"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:"</span></span><br><span class="line">hadoop@slave1:/$ <span class="built_in">source</span> environment</span><br></pre></td></tr></table></figure><h1 id="references"><a class="markdownIt-Anchor" href="#references"></a> References</h1><h2 id="hadoop"><a class="markdownIt-Anchor" href="#hadoop"></a> Hadoop</h2><p><a href="https://www.tutorialspoint.com/hadoop/hadoop_enviornment_setup.htm" target="_blank" rel="noopener">Hadoop Environment Configeration</a></p><p><a href="https://www.cnblogs.com/lanxuezaipiao/p/3525554.html" target="_blank" rel="noopener">一步步教你Hadoop多节点集群安装配置</a></p><p><a href="https://chaoge123456.github.io/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.html/" target="_blank" rel="noopener">Hadoop分布式集群搭建</a></p><p><a href="https://blog.csdn.net/zolalad/article/details/11470449" target="_blank" rel="noopener">Hadoop系统完全分布式集群搭建方法</a></p><h2 id="java-jdk"><a class="markdownIt-Anchor" href="#java-jdk"></a> Java JDK</h2><p><a href="https://stackoverflow.com/questions/14788345/how-to-install-the-jdk-on-ubuntu-linux" target="_blank" rel="noopener">How to install the JDK on Ubuntu Linux (OpenJDK)</a></p><p><a href="https://www.baeldung.com/oracle-jdk-vs-openjdk" target="_blank" rel="noopener">Differences between OpenJDK and Oracle JDK</a></p><h2 id="spark"><a class="markdownIt-Anchor" href="#spark"></a> Spark</h2><p><a href="https://opensource.com/article/18/11/pyspark-jupyter-notebook" target="_blank" rel="noopener">How to set up PySpark for your Jupyter notebook</a></p><p><a href="http://www.techguru.my/programming/install-spark-2-3-x-on-yarn-with-hadoop-3-x/" target="_blank" rel="noopener">Install Spark 2.3.x on YARN with Hadoop 3.x</a></p><p><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener">RDD Programming Guide</a></p><h2 id="jupyter-notebook"><a class="markdownIt-Anchor" href="#jupyter-notebook"></a> Jupyter Notebook</h2><p><a href="https://jupyter-notebook.readthedocs.io/en/stable/public_server.html" target="_blank" rel="noopener">Tutorial on setting up public jupyter notebook</a></p><h2 id="hdfs"><a class="markdownIt-Anchor" href="#hdfs"></a> HDFS</h2><p><a href="http://fibrevillage.com/storage/630-using-hdfs-command-line-to-manage-files-and-directories-on-hadoop" target="_blank" rel="noopener">Using hdfs command line to manage files and directories on Hadoop</a></p><h2 id="docker"><a class="markdownIt-Anchor" href="#docker"></a> Docker</h2><p><a href="https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04" target="_blank" rel="noopener">How To Install Docker On Ubuntu</a></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><msup><mi>a</mi><mn>2</mn></msup><mo>+</mo><msup><mi>b</mi><mn>2</mn></msup><mo>+</mo><msup><mi>c</mi><mn>2</mn></msup><msup><mo stretchy="false">)</mo><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">f(a,b,c) = (a^2+b^2+c^2)^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.9474379999999999em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span></p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
          <category> Big Data </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Setup </tag>
            
            <tag> Environment </tag>
            
            <tag> Installation </tag>
            
            <tag> Configuration </tag>
            
            <tag> Big Data </tag>
            
            <tag> Data Science </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/08/16/hello-world/"/>
      <url>/2019/08/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2><h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
